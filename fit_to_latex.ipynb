{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this notebook, you need to create a txt file which contains \n",
    "# the output results of xspec commands:{show free,show fit,error},\n",
    "# and you should paste the 'error' results of *all* parameters.\n",
    "\n",
    "# based on XSPEC version: 12.12.1, Not compatible with older versions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import imp\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "#relxill_v.2.0\n",
    "relxill_family = ['relconv','relconv_lp'\n",
    "                  'relxill','relxillCp',\n",
    "                  'relxilllp','relxilllpCp',\n",
    "                  'relline','relline_lp',\n",
    "                  'relxillNS',\n",
    "                  'xillver','xillverCp',\n",
    "                  'xillverD',\n",
    "                  'xillverNS']\n",
    "#relxill_nk_v.1.6.3\n",
    "relxill_nk_family = ['relxill_nk','relxillCp_nk',\n",
    "                     'relxill_nk2',\n",
    "                     'relxillD_nk',\n",
    "                     'relline_nk',\n",
    "                     'rellinedisk_nk',\n",
    "                     'rellinelp_nk',\n",
    "                     'rellinering_nk',\n",
    "                     'relxilllp_nk','relxilllpCp_nk',\n",
    "                     'relxilllpD_nk'\n",
    "                     'relxilldgrad_nk',\n",
    "                     'relxilldisk_nk',\n",
    "                     'relxillion_nk','relxillionCp_nk',\n",
    "                     'relxilllpion_nk','relxilllpionCp_nk',\n",
    "                     'relxillring_nk']\n",
    "#combine\n",
    "rel_family = ['relconv','relconv_lp',\n",
    "              'relxill','relxillCp','relxill_nk','relxillCp_nk','relxill_nk2',\n",
    "              'relxilllp','relxilllpCp','relxilllp_nk','relxilllpCp_nk',\n",
    "              'relxilllpD_nk',\n",
    "              'relline','relline_nk','rellinedisk_nk',\n",
    "              'relline_lp','rellinelp_nk',\n",
    "              'rellinering_nk',\n",
    "              'relxilldgrad_nk',\n",
    "              'relxilldisk_nk',\n",
    "              'relxillNS',\n",
    "              'relxillD_nk',\n",
    "              'relxillion_nk','relxillionCp_nk',\n",
    "              'relxilllpion_nk','relxilllpionCp_nk',\n",
    "              'relxillring_nk'\n",
    "              'xillver','xillverCp',\n",
    "              'xillverD',\n",
    "              'xillverNS']\n",
    "\n",
    "def add_something(strs:list,add:str):\n",
    "    new_strs = []\n",
    "    for str in strs:\n",
    "        new_strs.append(add+'_'+str)\n",
    "    return new_strs\n",
    "#norm    \n",
    "norm_rel = add_something(rel_family,'norm')\n",
    "norm_2_rel = add_something(rel_family,'norm_2')\n",
    "norm_3_rel = add_something(rel_family,'norm_3')\n",
    "norm_4_rel = add_something(rel_family,'norm_4')\n",
    "norm_rel_total = norm_rel + norm_2_rel + norm_3_rel + norm_4_rel\n",
    "#logxi\n",
    "logxi_xill = add_something(rel_family,'logxi')\n",
    "logxi_2_xill = add_something(rel_family,'logxi_2')\n",
    "logxi_3_xill = add_something(rel_family,'logxi_3')\n",
    "logxi_4_xill = add_something(rel_family,'logxi_4')\n",
    "logxi_xill_total = logxi_xill + logxi_2_xill + logxi_3_xill + logxi_4_xill\n",
    "# print(logxi_xill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = ['factor_1','factor_2','factor_3','factor_4']\n",
    "dGamma = ['dGamma_1','dGamma_2','dGamma_3','dGamma_4']\n",
    "crabcorNorm = ['crabcorNorm','crabcorNorm_1','crabcorNorm_2','crabcorNorm_3','crabcorNorm_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function may need to check or modify:\n",
    "#you need check if all the parameters strings are in the *parameters lib* in the function \"sort_parameters\"\n",
    "#if not, you should add them to \"sort_parameters\" and their respective latex strings in the function \"get_latex_of_parameters\"\n",
    "def sort_parameters(key_origin,debug=False):\n",
    "    #在此函数中设定表格中参数的顺序，根据需求修改\n",
    "    #创建一个字典，键是序列keys里的元素，值是对应的latex字符串\n",
    "    #需根据实际情况进行扩充或修改。\n",
    "    if debug == True:\n",
    "        print('key_origin:')\n",
    "        print(key_origin)\n",
    "    parameter_lib = ['MaxTau',#edge\n",
    "                     'nH',#tbabs\n",
    "                     'nH_2',#tbabs_2\n",
    "                     'Tin','Tin_1','Tin_2','Tin_3','Tin_4',\n",
    "                     'norm_diskbb','norm_1_diskbb','norm_2_diskbb','norm_3_diskbb',#diskbb\n",
    "                     'Mbh','Mdd','Dbh',#kerrbb\n",
    "                     'FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4',#simplcutx\n",
    "                     'norm_cutoffpl','kT_bb',#nthcomp or cutoffpl\n",
    "                     'norm_nthComp','norm_1_nthComp','norm_2_nthComp','norm_3_nthComp','norm_4_nthComp',\n",
    "                     'T0','kT','norm_compTT',#compTT\n",
    "                     'cov_frac',#thcomp\n",
    "                     'PhoIndex','PhoIndex_1','PhoIndex_2','PhoIndex_3','PhoIndex_4','Gamma_tau','Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma',#power-law component\n",
    "                     'kT_e','kTe','Ecut','E_cut','HighECut','HighECut_2','HighECut_3','HighECut_4', #E_cut\n",
    "                     'h',#lamppost corona\n",
    "                     'Index1','Index2','Index3','Rbr','Rbr1','Rbr2',#emission profile\n",
    "                     'Rin',\n",
    "                     'a',#black hole\n",
    "                     'Incl','i',#accretion disk\n",
    "                     'Afe',#abundance\n",
    "                     'xi_index',#reflection\n",
    "                     'refl_frac',\n",
    "                     'logN',\n",
    "                     'LineE','LineE_2','LineE_3','LineE_4','norm_gaussian','norm_2_gaussian','norm_3_gaussian','norm_4_gaussian','Sigma','Sigma_2','Sigma_3','Sigma_4',#guassian\n",
    "                     'Xpos',#xscat\n",
    "                     ] + logxi_xill_total + norm_rel_total + factor + dGamma + crabcorNorm\n",
    "    a = range(len(parameter_lib))\n",
    "    dict1 = dict(zip(a,parameter_lib))\n",
    "    if debug == True:\n",
    "        print('dict1:')\n",
    "        print(dict1)\n",
    "    dict2 = dict(zip(parameter_lib,a))\n",
    "    if debug == True:\n",
    "        print('dict2:')\n",
    "        print(dict2)\n",
    "    key_temp_1 = []\n",
    "    keys = []\n",
    "    for i in key_origin:\n",
    "        key_temp_1.append(dict2.get(i))\n",
    "    for a in key_temp_1:\n",
    "        if a == 'None':\n",
    "            print(\"you are missing some parameters in 'parameters_lib', please check it in function 'sort_parameters'\")\n",
    "    if debug == True:\n",
    "        print('key_temp_1:')\n",
    "        print(key_temp_1)\n",
    "    key_temp_2 = sorted(key_temp_1)  \n",
    "    for j in key_temp_2:\n",
    "        keys.append(dict1.get(j))\n",
    "    if debug == True:\n",
    "        print('keys:')\n",
    "        print(keys)  \n",
    "    return keys\n",
    "\n",
    "def get_latex_of_parameters(keys):\n",
    "    #we need to call another function to determine the output latex for some parameters\n",
    "    #such as: Index1,2, Rbr(nk or not nk)\n",
    "    #factor:output without the instrument names, you should fill it by yourself.\n",
    "    number = len(keys)\n",
    "    keys_latex = [None]*number\n",
    "    for i in range(number):\n",
    "        #edge\n",
    "        if keys[i] == 'MaxTau':\n",
    "            keys_latex[i] = '$\\\\tau_{\\\\tt max}$'\n",
    "        #tbabs\n",
    "        if keys[i] in ['nH','nH_2']:\n",
    "            keys_latex[i] = '$N_{\\\\rm H}$ [\\\\(10^{22}\\\\) cm\\\\(^{-2}\\\\)]'\n",
    "        #diskbb\n",
    "        if keys[i] in ['Tin','Tin_1','Tin_2','Tin_3','Tin_4']:\n",
    "            keys_latex[i] = '$T_{\\\\rm in}$'\n",
    "        #kerrbb\n",
    "        if keys[i] == 'Mbh':\n",
    "            keys_latex[i] = '$M$'\n",
    "        if keys[i] == 'Mdd':\n",
    "            keys_latex[i] = '$\\dot M$'\n",
    "        if keys[i] == 'Dbh':\n",
    "            keys_latex[i] = '$D$'\n",
    "        #simplcutx\n",
    "        if keys[i] in ['FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4','FracSctr_5']:\n",
    "            keys_latex[i] = '$f_{\\\\tt SC}$'\n",
    "        #nthcomp\n",
    "        if keys[i] == 'kT_bb':\n",
    "            keys_latex[i] = '$kT_{bb}$'\n",
    "        #compTT\n",
    "        if keys[i] == 'T0':\n",
    "            keys_latex[i] = '$T_{0}$'\n",
    "        if keys[i] == 'kT':\n",
    "            keys_latex[i] = '$T_{plasma}$'\n",
    "        #thcomp\n",
    "        if keys[i] == 'cov_frac':\n",
    "            keys_latex[i] = '$cov_{\\\\rm frac}$'\n",
    "        if keys[i] == 'Gamma_tau':\n",
    "            keys_latex[i] = '$\\\\Gamma_{\\\\tau}$'\n",
    "        #power-law component\n",
    "        if keys[i] in ['Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma','PhoIndex','PhoIndex_2','PhoIndex_3','PhoIndex_4']:\n",
    "            keys_latex[i] = '$\\\\Gamma$'\n",
    "        if keys[i] in ['kT_e','kTe']:\n",
    "            keys_latex[i] = '$kT_{\\\\rm e}$ [keV]'\n",
    "        if keys[i] in ['E_cut','Ecut','HighECut','HighECut','HighECut_2','HighECut_3','HighECut_4']:\n",
    "            keys_latex[i] = '$E_{\\\\rm cut}$'\n",
    "        #lamppost corona\n",
    "        if keys[i] == 'h':\n",
    "            keys_latex[i] = '$h$'\n",
    "        #emission profiles\n",
    "        if keys[i] == 'Index1':\n",
    "            keys_latex[i] = '$q_{\\\\rm in}$'\n",
    "        if keys[i] == 'Index2':\n",
    "            keys_latex[i] = '$q_{\\\\rm out}$ '\n",
    "        if keys[i] == 'Index3':\n",
    "            keys_latex[i] = '$q_{3}$'\n",
    "        if keys[i] == 'Rbr':\n",
    "            keys_latex[i] = '$R_{\\\\rm br}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr1':\n",
    "            keys_latex[i] = '$R_{\\\\rm br1}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr2':\n",
    "            keys_latex[i] = '$R_{\\\\rm br2}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rin':\n",
    "            keys_latex[i] = '$R_{\\\\rm in}$'\n",
    "        #black hole\n",
    "        if keys[i] == 'a':\n",
    "            keys_latex[i] = '$a_{*}$'\n",
    "        #accretion disk\n",
    "        if keys[i] in ['Incl','i']:\n",
    "            keys_latex[i] = '$i$ [deg]'\n",
    "        #abundance\n",
    "        if keys[i] == 'Afe':\n",
    "            keys_latex[i] = 'A$_{\\\\rm Fe}$'\n",
    "        #reflection\n",
    "        if keys[i] == 'xi_index':\n",
    "            keys_latex[i] = '$\\\\alpha_{\\\\xi}$' \n",
    "        if keys[i] == 'refl_frac':\n",
    "            keys_latex[i] = '$R_{\\\\rm f}$'\n",
    "        if keys[i] == 'logN':\n",
    "            keys_latex[i] = 'log${\\\\rm N}$'\n",
    "        #guassian\n",
    "        if keys[i] in ['LineE','LineE_2','LineE_3','LineE_4']:\n",
    "            keys_latex[i] = '$E_{\\\\rm line}$'\n",
    "        if keys[i] in ['Sigma','Sigma_2','Sigma_3','Sigma_4']:\n",
    "            keys_latex[i] = '$\\\\sigma$'\n",
    "        #xscat\n",
    "        if keys[i] == 'Xpos':\n",
    "            keys_latex[i] = '$x$'\n",
    "        #norm\n",
    "        if keys[i].split('_')[0] == 'norm':\n",
    "            if len(keys[i].split('_')) == 2:\n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[1] + '})'\n",
    "            else: \n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[2] + keys[i].split('_')[1] + '})'\n",
    "        #logxi\n",
    "        if keys[i].split('_')[0] == 'logxi':\n",
    "            if keys[i].split('_')[1] in ['2','3','4']:\n",
    "                keys_latex[i] = 'log${\\\\xi}$(' + keys[i].split('_')[2] + keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "            else:\n",
    "                keys_latex[i] = 'log${\\\\xi}$('+ keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "        #factor:output without the instrument names, you should fill it by yourself in latex.\n",
    "        if keys[i].split('_')[0] == 'factor':\n",
    "            keys_latex[i] = '$C_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'dGamma':\n",
    "            keys_latex[i] = '$dGamma_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'crabcorNorm':\n",
    "            keys_latex[i] = '$crabcorNorm_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "    par_latex = dict(zip(keys,keys_latex))\n",
    "    return par_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt file pre-treatment\n",
    "def do_something2multifiles(infiles:list):\n",
    "    for infile in infiles:\n",
    "        delete_hashtag_and_blank_line(infile)\n",
    "        add_index2par_single_file(infile)\n",
    "        delete_useless_str(infile)\n",
    "        mod_nk(infile)\n",
    "        i2incl(infile)\n",
    "        show_par2show_free(infile)\n",
    "    check_Rbr(infiles)\n",
    "        \n",
    "def delete_hashtag_and_blank_line(file): \n",
    "    # \"#\"and blank line should be removed first.\n",
    "    file_data = \"\"\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if '#' in line:\n",
    "                    line = line.replace('#','')\n",
    "                if line == '\\n':\n",
    "                    line = line.strip(\"\\n\")           \n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "\n",
    "def delete_useless_str(file):\n",
    "    # 请先保证文档没有空行。\n",
    "    file_data = \"\"   \n",
    "    str_delete = ['Apparent','Current','and','but','Suggest',\n",
    "                  'Error','***','caused','Parameter','***Warning:','Due','Suggest','pparent','Please','will automatically exit']    \n",
    "    with open(file, \"r\") as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line.split() == []:\n",
    "                continue\n",
    "            if line.split()[0] not in str_delete:\n",
    "                file_data += line   \n",
    "    with open(file,\"w\",encoding=\"utf-8\") as output:\n",
    "        output.write(file_data) \n",
    "    \n",
    "def add_index2par_single_file(infile):\n",
    "    #example: factor -> factor_2; factor -> factor_3\n",
    "    #example: nH -> nH_2\n",
    "    file_data = \"\"\n",
    "    index = ''\n",
    "    with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if len(lines[i].split()) < 3:\n",
    "                continue\n",
    "            elif lines[i].split()[0] == 'Data' and lines[i].split()[2] != '1':\n",
    "                #第零行:数据组标题\n",
    "                index = lines[i].split()[2]\n",
    "                #第一行\n",
    "                factor = lines[i+1].split()[3]\n",
    "                if factor == 'factor':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('factor','factor'+'_'+index)\n",
    "                if factor == 'dGamma':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('dGamma','dGamma'+'_'+index)\n",
    "                if factor == 'Tin':\n",
    "                    lines[i+1] = lines[i+1].replace('Tin','Tin'+'_'+index)\n",
    "                if factor == 'FracSctr':\n",
    "                    lines[i+1] = lines[i+1].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                if factor == 'PhoIndex':\n",
    "                    lines[i+1] = lines[i+1].replace('PhoIndex','PhoIndex'+'_'+index)\n",
    "                if factor == 'crabcorNorm':\n",
    "                    lines[i+1] = lines[i+1].replace('crabcorNorm','crabcorNorm'+'_'+index)\n",
    "                #第二行\n",
    "                if len(lines[i+2].split()) > 3:\n",
    "                    factor2 = lines[i+2].split()[3]\n",
    "                    if factor2 == 'nH':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('nH','nH'+'_'+index)\n",
    "                    if factor2 == 'crabcorNorm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('crabcorNorm','crabcorNorm'+'_'+index)\n",
    "                    if factor2 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('norm','norm'+'_'+index)\n",
    "                    if factor2 == 'Tin':\n",
    "                        lines[i+2] = lines[i+2].replace('Tin','Tin'+'_'+index)\n",
    "                    if factor2 == 'HighECut':\n",
    "                        lines[i+2] = lines[i+2].replace('HighECut','HighECut'+'_'+index)\n",
    "                #第三行\n",
    "                if len(lines[i+3].split()) > 3:\n",
    "                    factor3 = lines[i+3].split()[3]\n",
    "                    if factor3 == 'Tin':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+3] = lines[i+3].replace('Tin','Tin'+'_'+index)\n",
    "                    if factor3 == 'FracSctr':\n",
    "                        lines[i+3] = lines[i+3].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                #第四行\n",
    "                if len(lines[i+4].split()) > 3:\n",
    "                    factor4 = lines[i+4].split()[3]\n",
    "                    if factor4 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+4] = lines[i+4].replace('norm','norm'+'_'+index)\n",
    "                    if factor4 == 'Tin':\n",
    "                        lines[i+4] = lines[i+4].replace('Tin','Tin'+'_'+index)  \n",
    "                    if factor4 == 'Gamma':\n",
    "                        lines[i+4] = lines[i+4].replace('Gamma','Gamma'+'_'+index)   \n",
    "                #第五行      \n",
    "                if len(lines[i+5].split()) > 3:\n",
    "                    factor5 = lines[i+5].split()[3]\n",
    "                    if factor5 == 'logxi':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+5] = lines[i+5].replace('logxi','logxi'+'_'+index)    \n",
    "                #第六行      \n",
    "                if len(lines[i+6].split()) > 3:\n",
    "                    factor6 = lines[i+6].split()[3]\n",
    "                    if factor6 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+6] = lines[i+6].replace('norm','norm'+'_'+index) \n",
    "                #第七行\n",
    "                if len(lines[i+7].split()) > 3:\n",
    "                    factor7 = lines[i+7].split()[3]\n",
    "                    if factor7 == 'LineE':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+7] = lines[i+7].replace('LineE','LineE'+'_'+index) \n",
    "                #第八行\n",
    "                if len(lines[i+8].split()) > 3:\n",
    "                    factor8 = lines[i+8].split()[3]\n",
    "                    if factor8 == 'Sigma':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+8] = lines[i+8].replace('Sigma','Sigma'+'_'+index) \n",
    "                #第九行\n",
    "                if len(lines[i+9].split()) > 3:\n",
    "                    factor9 = lines[i+9].split()[3]\n",
    "                    if factor9 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+9] = lines[i+9].replace('norm','norm'+'_'+index) \n",
    "        for line in lines:\n",
    "            file_data += line\n",
    "    with open(infile, \"w\", encoding=\"utf-8\") as f: \n",
    "        f.write(file_data)      \n",
    "\n",
    "def mod_nk(file):\n",
    "    #因为nk后缀会破坏按行切分\n",
    "    # 替换文件中的字符串,把rexill_nk的后缀nk去掉。这个函数对需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace('_nk','_nk ')\n",
    "            line = line.replace('relxilllpCp','relxilllpCp ')\n",
    "            file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "           \n",
    "def check_Rbr(files:list):\n",
    "    #first, make a judgement and decide whether to replace 'Rbr' with 'Rbr_1'\n",
    "    a = 0\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\" utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if 'Rbr_2' in line.split():\n",
    "                    a += 1\n",
    "    if a > 0:        \n",
    "        for file in files:\n",
    "        # 替换文件中的字符串,把Rbr替换为Rbr_1。这是因为我们需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "            file_data = \"\"\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if ('Rbr' in line) and ('Rbr1' not in line) and ('Rbr2' not in line):\n",
    "                        line = line.replace('Rbr','Rbr1')\n",
    "                    file_data += line\n",
    "            with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(file_data)\n",
    "                f.close()  \n",
    "                \n",
    "def i2incl(file):\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) < 4:\n",
    "                file_data += line\n",
    "            else:\n",
    "                if line.split()[3] == 'i':\n",
    "                    line = line.replace('i','Incl')\n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)     \n",
    "          \n",
    "def show_par2show_free(file):\n",
    "    #get error list\n",
    "    error_list = []\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) == 4:\n",
    "                if len(line.split()[-1].split(',')) == 2:\n",
    "                    error_list.append(line.split()[0])\n",
    "    #read show par and copy some fo them\n",
    "    file_data = \"\"\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'par' and line.split()[1] == 'comp':\n",
    "                    start_index = int(x[0]) + 2\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:               \n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'Fit':\n",
    "                    end_index = int(x[0]) - 1\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            copy = True\n",
    "            index = x[0]\n",
    "            line = x[1]\n",
    "            if index >= start_index and index <= end_index:\n",
    "                if len(line.split()) > 1:\n",
    "                    if line.split()[0] == 'Data':\n",
    "                        copy = True\n",
    "                    elif line.split()[0] in error_list:\n",
    "                        copy = True\n",
    "                    else:\n",
    "                        copy = False        \n",
    "                else:\n",
    "                    copy = True\n",
    "            else:\n",
    "                copy = True     \n",
    "            if copy == True:\n",
    "                file_data += line\n",
    "    #write down the new file\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters values from the data\n",
    "def get_par_best_error(infile):\n",
    "    \n",
    "    index = []\n",
    "    parameter = []\n",
    "    best_fit = []\n",
    "    bound = []\n",
    "    data_group_index = ''\n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                if (line.split()[3] in ['norm','norm_1','norm_2','norm_3','norm_4'] or line.split()[3] in ['logxi','logxi_2','logxi_3','logxi_4']):\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3] + \"_\" + line.split()[2])\n",
    "                    #example: 'norm' + '_' + 'nthcomp'\n",
    "                else:\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3])\n",
    "    parameters = dict(zip(index,parameter))\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                index.append(line.split()[0])\n",
    "                best_fit.append(line.split()[-3])\n",
    "    best = dict(zip(index,best_fit)) \n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>3:\n",
    "            if line.split()[-1][-1]==\")\":\n",
    "                if len(line.split()[-1].split(','))>1.1:\n",
    "                    index.append(line.split()[0])\n",
    "                    bound.append([line.split()[1], line.split()[2]])\n",
    "                    \n",
    "    bounds = dict(zip(index,bound))\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return parameters, best, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latex elements\n",
    "def get_latex_elements_single_file(infile,debug=False):\n",
    "    import imp\n",
    "    import error2latex as el\n",
    "    imp.reload(el)\n",
    "    \n",
    "    parameter, best_fit, bounds = get_par_best_error(infile)\n",
    "    \n",
    "    #index = []\n",
    "    par = []\n",
    "    latex_c = []\n",
    "    \n",
    "    if len(best_fit)!=len(bounds):\n",
    "        print(\"Error: best-fit parameters do not match the number of uncertainties\")\n",
    "        print(f\"Number of free parameters: {len(best_fit)}, number of boundaries: {len(bounds)}\")\n",
    "    \n",
    "    for key in best_fit.keys():\n",
    "        name = parameter[key]\n",
    "        best = best_fit[key]\n",
    "        lower = bounds[key][0]\n",
    "        upper = bounds[key][1]\n",
    "        string, value_base, err_low_base, err_high_base = el.get_xspec_error(best, lower, upper) \n",
    "        \n",
    "        #index.append(key)\n",
    "        par.append(name)\n",
    "        latex_c.append(string)    \n",
    "        \n",
    "       # print(string)\n",
    "    #result = dict(zip(index,latex_c))\n",
    "    # print(par)\n",
    "    result = dict(zip(par,latex_c))\n",
    "    if debug == True:\n",
    "        print('Hey! latex elements have been got from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_latex_elements_multiple_file(infiles,debug=False):\n",
    "    number = len(infiles)\n",
    "    elements = [None]*number\n",
    "    for i in range(number):\n",
    "        if debug == False:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i])\n",
    "        else:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i],debug=True)\n",
    "    pars = []\n",
    "    \n",
    "    for i in range(number):\n",
    "        pars = pars + list(elements[i].keys())\n",
    "    keys_origin = list(set(pars))\n",
    "    \n",
    "    if debug == True:\n",
    "        keys = sort_parameters(keys_origin,debug=True)\n",
    "    else:\n",
    "        keys = sort_parameters(keys_origin)\n",
    "        \n",
    "    return elements, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics values and its latex code\n",
    "def get_chi_sq_and_AICc_single_file(infile):\n",
    "# based on XSPEC version: 12.12.1, not Not compatible with older versions! \n",
    "# because the xspec outputs of \"show fit\" are different in version: 12.12.1 \n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    index = ['chisq','dof','reduced_chisq','N-bin','N-par','AICc']\n",
    "    value = [None]*6\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.split()[0] == 'Test' and line.split()[-1] == 'bins.':\n",
    "            value[3] = int(line.split()[-2])\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4:\n",
    "            if line.split()[-1] == 'd.o.f.':\n",
    "                value[0] = float(line.split()[3])\n",
    "                value[1] = int(line.split()[-2])\n",
    "                value[2] = float(\"{:.5f}\".format(value[0] / value[1]))\n",
    "\n",
    "    value[4] = value[3] - value[1]\n",
    "    \n",
    "    value[5] = float(\"{:.2f}\".format(value[0] + 2*value[4] + 2*value[4]*(value[4]+1)/(value[3]-value[4]-1)))\n",
    "    \n",
    "    result = dict(zip(index,value))\n",
    "    \n",
    "#     print('got statistic from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_chi_sq_and_AICc_multiple_files(infiles, outfile):\n",
    "    \n",
    "    number = len(infiles)\n",
    "    chisq, dof, reduced_chisq, AICc = [None]*number, [None]*number, [None]*number, [None]*number\n",
    "    for i in range(number):\n",
    "        chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('chisq')\n",
    "        dof[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('dof')\n",
    "        reduced_chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('reduced_chisq')\n",
    "        AICc[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('AICc')\n",
    "\n",
    "    string = '$\\chi^2$ /dof'\n",
    "    \n",
    "    string_AICc = 'AICc'\n",
    "    \n",
    "    for n in range(number):\n",
    "        string = string + ' & ' +'\\\\tabincell{c}{' + str(chisq[n]) + '/' + str(dof[n]) + '=\\\\\\\\' + str(reduced_chisq[n]) + '}'\n",
    "        string_AICc = string_AICc + ' & ' + str(AICc[n])\n",
    "        \n",
    "    print('\\\\hline' + '\\n\\n' + string + '\\\\\\\\' + '\\n\\n' + string_AICc +  '\\\\\\\\' + '\\n\\n' + '\\\\hline' + '\\n', file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally,print the full latex code\n",
    "def print_final_latex_code(infiles:list,model_name:list,debug=False,output_filename='latex_table_output.txt'):\n",
    "    # Open the file for writing\n",
    "    output_file = open(output_filename, \"w\")\n",
    "        \n",
    "    do_something2multifiles(infiles)\n",
    "    if debug == True:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles,debug=True)\n",
    "    else:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles)\n",
    "    #去掉多余的减号\n",
    "    for i in range(len(infiles)):\n",
    "        for key in elements[i].keys():\n",
    "            elements[i][key] = elements[i][key].replace('{--','{-')\n",
    "    if debug == True:\n",
    "        print('elements: ')\n",
    "        print(elements)\n",
    "    \n",
    "    par_latex = get_latex_of_parameters(keys)\n",
    "    # print(par_latex)\n",
    "    \n",
    "    # newcommand reminder:\n",
    "    \n",
    "    print(\"please copy this to the front of your .tex file in order to use commands:'tabincell':\\n\", file=output_file)\n",
    "    print(\"\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}\\n\", file=output_file)\n",
    "    \n",
    "    print(\"###########################################################################################################################\", file=output_file)\n",
    "    \n",
    "    #resizebox or not\n",
    "    if len(infiles) > 5:\n",
    "        print('\\n'+'%please copy this line to the front of your .tex document in order to use \\\\tabincell: '+ '\\n'\n",
    "              +'\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}' + '\\n', file=output_file)\n",
    "        \n",
    "        print(\"###########################################################################################################################\", file=output_file)\n",
    "        \n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n' + '\\\\resizebox{\\\\textwidth}{70mm}{' , file=output_file)\n",
    "    else:\n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n', file=output_file)\n",
    "    #table\n",
    "    chart = '' \n",
    "    for i in range(len(infiles)):\n",
    "        chart += 'c'\n",
    "\n",
    "    print('\\\\begin{tabular}{l' + chart + '}'+ '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    model = 'Model'\n",
    "    for i in range(len(infiles)):\n",
    "        model += (' & ' + 'Model ' + model_name[i])\n",
    "    \n",
    "    print(model + '\\\\\\\\' + '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    for par in keys:\n",
    "        string = par_latex.get(par)\n",
    "        for n in range(len(infiles)):\n",
    "            if par in set(list(elements[n].keys())):\n",
    "    #                 print(string)\n",
    "                string = string + ' & '+ elements[n][par]\n",
    "            else:\n",
    "                string = string + ' & ' + ' - '\n",
    "        print(string + '\\\\\\\\' + '\\n', file=output_file)\n",
    "\n",
    "    print_chi_sq_and_AICc_multiple_files(infiles, output_file)\n",
    "    \n",
    "    #print AICc\n",
    "    \n",
    "    if len(infiles) > 5:\n",
    "        print('\\\\end{tabular}' + '\\n' + '}' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    else:\n",
    "        print('\\\\end{tabular}' + '\\n' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    # Close the file\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mo_2C-2_gamma-Tin_best-fit.txt', 'mo_2A-2_coupled_pl-eemod-ra.txt', 'mo_1A-2_same-Tin_best-fit.txt', 'mo_2A-2_undecoupled_scattered_pl-eemod-ra.txt', 'mo2_ign_3-4_nustar_pl-eemod-delchi.txt', 'mo_2A-2_fsc-Tin_best-fit.txt', 'simp_disk+relionCp-nk_+xillcp_q2-free_best-fit.txt', 'mo_2A-2_undecoupled_pl-eemod-ra.txt', 'steppar_incl_mo2_errorbar.txt', 'mo_1A-2_coupled_pl-eemod-ra.txt', 'mo_2A-1_pl-eemod-ra.txt', 'mo_2C-2_4g_best-fit.txt', 'mo_2B-2_gamma-Tin_896_pl-eemod-ra.txt', 'mo_2C-2_fsc-Tin_best-fit.txt', 'mo_1C-1_pl-eemod-ra.txt', 'mo_1A-2_new-best-fit_852_Tin-norm-nthcomp.txt', 'mo2_best-fit.txt', 'mo_2A-1_all_pl-eemod.txt', 'lightcurve_100s_3-79keV.txt', 'mo_2A-2_scattered_pl-eemod-ra.txt', 'steppar_incl_mo1_new.txt', 'mo_1A-2_undecoupled_pl-eemod-ra.txt', 'readme_model-list.txt', 'mo_2A-1_scattered_pl-eemod.txt', 'mo_2A-2_decouple_pl-ra.txt', 'mo_2C-1_pl-eemod-ra.txt', 'latex_table_output.txt', 'mo_1A-2_ni2200760104_Tin-gamma_pl-eemod-ra.txt', 'mo_2C-2_fsc-Tin_pl-eemod-ra.txt', 'mo_2A-2_coupled_scattered_pl-eemod-ra.txt', 'mo1_bes-fit.txt', 'diskbb_nthcomp_ni22014_pl-ra.txt', 'simulation_mo1_NuSTAR_pl-eemod-ra.txt', 'mo_2C-1_scattered_pl-eemod-ra.txt', 'steppar_incl_mo2.txt', 'steppar_incl_mo2_new.txt', 'mo_2B-2_fsc-Tin_best-fit.txt', 'simp_disk+relionCp-nk_+xillcp_q2-free_pl-eemod-ra.txt', 'mo_2C-2_gamma-Tin_pl-eemod-ra.txt', 'mo_2A-2_ni2200760104_Tin-gamma_pl-eemod-ra.txt', 'mo_2A-2_4g_best-fit1.txt', 'mo2_local_best-fit.txt', 'mo_2A-1_scattered_pl-eemod-ra.txt', 'mo_1B-2_ni22104_Tin-gamma_best-fit.txt', 'mo_1A-2_coupled_best-fit.txt', 'mo_2A-2_fsc-Tin_874_pl-eemod-ra.txt', 'mo_2A-2_coupled_best-fit.txt', 'mo_1C-2_Tin-gamma_pl-eemod-ra.txt', 'lightcurve_hardness_time_10-20vs3-10.txt', 'mo_2B-2_fsc-Tin_pl-eemod-ra.txt', 'mo_2B-2_scattered_pl-eemod-ra.txt', 'lightcurve_hardness_time_20-79vs3-10.txt', 'steppar_incl_mo1.txt', 'mo_2A-2_3g_new-best-fit_pl-eemod-delchi_scattered.txt', 'mo_2B-1_scattered_pl-eemod-ra.txt', 'mo_1B-2_ni22104_Tin-gamma_pl-eemod-ra.txt', 'mo1_local_best-fit.txt', 'mo_2A-2_fsc-Tin_new-fit.txt', 'simp_disk+relionCp-nk_+xillcp_q2-free_pl-chi.txt', 'steppar_a_mo2.txt', 'mo_1A-2_ni22104_Tin-gamma_pl-eemod-ra.txt', 'steppar_incl_mo1_errorbar.txt', 'mo_2C-2_scattered_pl-eemod-ra.txt', 'mo_2A-2_ni22104_TIn-gamma_best-fit.txt', 'steppar_a_mo1.txt', 'mo_2A-2_3g_new-best-fit_pl-eemod-delchi.txt', 'mo_1C-2_Tin-gamma_best-fit.txt', 'mo2_ign_3-4_nustar_best-fit.txt', 'simulation_mo1_NuSTAR_best-fit.txt', 'mo_1B-2_ni2200760104_Tin-gamma_best-fit.txt', 'mo_2B-2_gamma-Tin_896_best-fit.txt', 'mo_1A-2_ni22104_Tin-gamma_best-fit.txt', 'mo_1B-2_ni2200760104_Tin-gamma_pl-eemod-ra.txt', 'mo_2A-2_fsc-Tin_pl-eemod-ra.txt']\n"
     ]
    }
   ],
   "source": [
    "#get txt_file list\n",
    "path = './'\n",
    "dirs = os.listdir(path)\n",
    "txt_files = []\n",
    "for name in dirs:\n",
    "    if name.split('.')[-1] == 'txt':\n",
    "        txt_files.append(name)\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! latex elements have been got from mo1_bes-fit.txt\n",
      "Hey! latex elements have been got from mo2_best-fit.txt\n",
      "Hey! latex elements have been got from mo1_local_best-fit.txt\n",
      "Hey! latex elements have been got from mo2_local_best-fit.txt\n",
      "key_origin:\n",
      "['norm_diskbb', 'Gamma', 'crabcorNorm_2', 'MaxTau', 'nH', 'norm_relxillionCp_nk', 'crabcorNorm_3', 'Index1', 'xi_index', 'Afe', 'Index2', 'Rbr1', 'kT_e', 'Incl', 'a', 'Xpos', 'dGamma_3', 'norm_nthComp', 'logxi_relxillionCp_nk', 'FracSctr', 'Tin']\n",
      "dict1:\n",
      "{0: 'MaxTau', 1: 'nH', 2: 'nH_2', 3: 'Tin', 4: 'Tin_1', 5: 'Tin_2', 6: 'Tin_3', 7: 'Tin_4', 8: 'norm_diskbb', 9: 'norm_1_diskbb', 10: 'norm_2_diskbb', 11: 'norm_3_diskbb', 12: 'Mbh', 13: 'Mdd', 14: 'Dbh', 15: 'FracSctr', 16: 'FracSctr_1', 17: 'FracSctr_2', 18: 'FracSctr_3', 19: 'FracSctr_4', 20: 'norm_cutoffpl', 21: 'kT_bb', 22: 'norm_nthComp', 23: 'norm_1_nthComp', 24: 'norm_2_nthComp', 25: 'norm_3_nthComp', 26: 'norm_4_nthComp', 27: 'T0', 28: 'kT', 29: 'norm_compTT', 30: 'cov_frac', 31: 'PhoIndex', 32: 'PhoIndex_1', 33: 'PhoIndex_2', 34: 'PhoIndex_3', 35: 'PhoIndex_4', 36: 'Gamma_tau', 37: 'Gamma', 38: 'Gamma_1', 39: 'Gamma_2', 40: 'Gamma_3', 41: 'Gamma_4', 42: 'gamma', 43: 'kT_e', 44: 'kTe', 45: 'Ecut', 46: 'E_cut', 47: 'HighECut', 48: 'HighECut_2', 49: 'HighECut_3', 50: 'HighECut_4', 51: 'h', 52: 'Index1', 53: 'Index2', 54: 'Index3', 55: 'Rbr', 56: 'Rbr1', 57: 'Rbr2', 58: 'Rin', 59: 'a', 60: 'Incl', 61: 'i', 62: 'Afe', 63: 'xi_index', 64: 'refl_frac', 65: 'logN', 66: 'LineE', 67: 'LineE_2', 68: 'LineE_3', 69: 'LineE_4', 70: 'norm_gaussian', 71: 'norm_2_gaussian', 72: 'norm_3_gaussian', 73: 'norm_4_gaussian', 74: 'Sigma', 75: 'Sigma_2', 76: 'Sigma_3', 77: 'Sigma_4', 78: 'Xpos', 79: 'logxi_relconv', 80: 'logxi_relconv_lp', 81: 'logxi_relxill', 82: 'logxi_relxillCp', 83: 'logxi_relxill_nk', 84: 'logxi_relxillCp_nk', 85: 'logxi_relxill_nk2', 86: 'logxi_relxilllp', 87: 'logxi_relxilllpCp', 88: 'logxi_relxilllp_nk', 89: 'logxi_relxilllpCp_nk', 90: 'logxi_relxilllpD_nk', 91: 'logxi_relline', 92: 'logxi_relline_nk', 93: 'logxi_rellinedisk_nk', 94: 'logxi_relline_lp', 95: 'logxi_rellinelp_nk', 96: 'logxi_rellinering_nk', 97: 'logxi_relxilldgrad_nk', 98: 'logxi_relxilldisk_nk', 99: 'logxi_relxillNS', 100: 'logxi_relxillD_nk', 101: 'logxi_relxillion_nk', 102: 'logxi_relxillionCp_nk', 103: 'logxi_relxilllpion_nk', 104: 'logxi_relxilllpionCp_nk', 105: 'logxi_relxillring_nkxillver', 106: 'logxi_xillverCp', 107: 'logxi_xillverD', 108: 'logxi_xillverNS', 109: 'logxi_2_relconv', 110: 'logxi_2_relconv_lp', 111: 'logxi_2_relxill', 112: 'logxi_2_relxillCp', 113: 'logxi_2_relxill_nk', 114: 'logxi_2_relxillCp_nk', 115: 'logxi_2_relxill_nk2', 116: 'logxi_2_relxilllp', 117: 'logxi_2_relxilllpCp', 118: 'logxi_2_relxilllp_nk', 119: 'logxi_2_relxilllpCp_nk', 120: 'logxi_2_relxilllpD_nk', 121: 'logxi_2_relline', 122: 'logxi_2_relline_nk', 123: 'logxi_2_rellinedisk_nk', 124: 'logxi_2_relline_lp', 125: 'logxi_2_rellinelp_nk', 126: 'logxi_2_rellinering_nk', 127: 'logxi_2_relxilldgrad_nk', 128: 'logxi_2_relxilldisk_nk', 129: 'logxi_2_relxillNS', 130: 'logxi_2_relxillD_nk', 131: 'logxi_2_relxillion_nk', 132: 'logxi_2_relxillionCp_nk', 133: 'logxi_2_relxilllpion_nk', 134: 'logxi_2_relxilllpionCp_nk', 135: 'logxi_2_relxillring_nkxillver', 136: 'logxi_2_xillverCp', 137: 'logxi_2_xillverD', 138: 'logxi_2_xillverNS', 139: 'logxi_3_relconv', 140: 'logxi_3_relconv_lp', 141: 'logxi_3_relxill', 142: 'logxi_3_relxillCp', 143: 'logxi_3_relxill_nk', 144: 'logxi_3_relxillCp_nk', 145: 'logxi_3_relxill_nk2', 146: 'logxi_3_relxilllp', 147: 'logxi_3_relxilllpCp', 148: 'logxi_3_relxilllp_nk', 149: 'logxi_3_relxilllpCp_nk', 150: 'logxi_3_relxilllpD_nk', 151: 'logxi_3_relline', 152: 'logxi_3_relline_nk', 153: 'logxi_3_rellinedisk_nk', 154: 'logxi_3_relline_lp', 155: 'logxi_3_rellinelp_nk', 156: 'logxi_3_rellinering_nk', 157: 'logxi_3_relxilldgrad_nk', 158: 'logxi_3_relxilldisk_nk', 159: 'logxi_3_relxillNS', 160: 'logxi_3_relxillD_nk', 161: 'logxi_3_relxillion_nk', 162: 'logxi_3_relxillionCp_nk', 163: 'logxi_3_relxilllpion_nk', 164: 'logxi_3_relxilllpionCp_nk', 165: 'logxi_3_relxillring_nkxillver', 166: 'logxi_3_xillverCp', 167: 'logxi_3_xillverD', 168: 'logxi_3_xillverNS', 169: 'logxi_4_relconv', 170: 'logxi_4_relconv_lp', 171: 'logxi_4_relxill', 172: 'logxi_4_relxillCp', 173: 'logxi_4_relxill_nk', 174: 'logxi_4_relxillCp_nk', 175: 'logxi_4_relxill_nk2', 176: 'logxi_4_relxilllp', 177: 'logxi_4_relxilllpCp', 178: 'logxi_4_relxilllp_nk', 179: 'logxi_4_relxilllpCp_nk', 180: 'logxi_4_relxilllpD_nk', 181: 'logxi_4_relline', 182: 'logxi_4_relline_nk', 183: 'logxi_4_rellinedisk_nk', 184: 'logxi_4_relline_lp', 185: 'logxi_4_rellinelp_nk', 186: 'logxi_4_rellinering_nk', 187: 'logxi_4_relxilldgrad_nk', 188: 'logxi_4_relxilldisk_nk', 189: 'logxi_4_relxillNS', 190: 'logxi_4_relxillD_nk', 191: 'logxi_4_relxillion_nk', 192: 'logxi_4_relxillionCp_nk', 193: 'logxi_4_relxilllpion_nk', 194: 'logxi_4_relxilllpionCp_nk', 195: 'logxi_4_relxillring_nkxillver', 196: 'logxi_4_xillverCp', 197: 'logxi_4_xillverD', 198: 'logxi_4_xillverNS', 199: 'norm_relconv', 200: 'norm_relconv_lp', 201: 'norm_relxill', 202: 'norm_relxillCp', 203: 'norm_relxill_nk', 204: 'norm_relxillCp_nk', 205: 'norm_relxill_nk2', 206: 'norm_relxilllp', 207: 'norm_relxilllpCp', 208: 'norm_relxilllp_nk', 209: 'norm_relxilllpCp_nk', 210: 'norm_relxilllpD_nk', 211: 'norm_relline', 212: 'norm_relline_nk', 213: 'norm_rellinedisk_nk', 214: 'norm_relline_lp', 215: 'norm_rellinelp_nk', 216: 'norm_rellinering_nk', 217: 'norm_relxilldgrad_nk', 218: 'norm_relxilldisk_nk', 219: 'norm_relxillNS', 220: 'norm_relxillD_nk', 221: 'norm_relxillion_nk', 222: 'norm_relxillionCp_nk', 223: 'norm_relxilllpion_nk', 224: 'norm_relxilllpionCp_nk', 225: 'norm_relxillring_nkxillver', 226: 'norm_xillverCp', 227: 'norm_xillverD', 228: 'norm_xillverNS', 229: 'norm_2_relconv', 230: 'norm_2_relconv_lp', 231: 'norm_2_relxill', 232: 'norm_2_relxillCp', 233: 'norm_2_relxill_nk', 234: 'norm_2_relxillCp_nk', 235: 'norm_2_relxill_nk2', 236: 'norm_2_relxilllp', 237: 'norm_2_relxilllpCp', 238: 'norm_2_relxilllp_nk', 239: 'norm_2_relxilllpCp_nk', 240: 'norm_2_relxilllpD_nk', 241: 'norm_2_relline', 242: 'norm_2_relline_nk', 243: 'norm_2_rellinedisk_nk', 244: 'norm_2_relline_lp', 245: 'norm_2_rellinelp_nk', 246: 'norm_2_rellinering_nk', 247: 'norm_2_relxilldgrad_nk', 248: 'norm_2_relxilldisk_nk', 249: 'norm_2_relxillNS', 250: 'norm_2_relxillD_nk', 251: 'norm_2_relxillion_nk', 252: 'norm_2_relxillionCp_nk', 253: 'norm_2_relxilllpion_nk', 254: 'norm_2_relxilllpionCp_nk', 255: 'norm_2_relxillring_nkxillver', 256: 'norm_2_xillverCp', 257: 'norm_2_xillverD', 258: 'norm_2_xillverNS', 259: 'norm_3_relconv', 260: 'norm_3_relconv_lp', 261: 'norm_3_relxill', 262: 'norm_3_relxillCp', 263: 'norm_3_relxill_nk', 264: 'norm_3_relxillCp_nk', 265: 'norm_3_relxill_nk2', 266: 'norm_3_relxilllp', 267: 'norm_3_relxilllpCp', 268: 'norm_3_relxilllp_nk', 269: 'norm_3_relxilllpCp_nk', 270: 'norm_3_relxilllpD_nk', 271: 'norm_3_relline', 272: 'norm_3_relline_nk', 273: 'norm_3_rellinedisk_nk', 274: 'norm_3_relline_lp', 275: 'norm_3_rellinelp_nk', 276: 'norm_3_rellinering_nk', 277: 'norm_3_relxilldgrad_nk', 278: 'norm_3_relxilldisk_nk', 279: 'norm_3_relxillNS', 280: 'norm_3_relxillD_nk', 281: 'norm_3_relxillion_nk', 282: 'norm_3_relxillionCp_nk', 283: 'norm_3_relxilllpion_nk', 284: 'norm_3_relxilllpionCp_nk', 285: 'norm_3_relxillring_nkxillver', 286: 'norm_3_xillverCp', 287: 'norm_3_xillverD', 288: 'norm_3_xillverNS', 289: 'norm_4_relconv', 290: 'norm_4_relconv_lp', 291: 'norm_4_relxill', 292: 'norm_4_relxillCp', 293: 'norm_4_relxill_nk', 294: 'norm_4_relxillCp_nk', 295: 'norm_4_relxill_nk2', 296: 'norm_4_relxilllp', 297: 'norm_4_relxilllpCp', 298: 'norm_4_relxilllp_nk', 299: 'norm_4_relxilllpCp_nk', 300: 'norm_4_relxilllpD_nk', 301: 'norm_4_relline', 302: 'norm_4_relline_nk', 303: 'norm_4_rellinedisk_nk', 304: 'norm_4_relline_lp', 305: 'norm_4_rellinelp_nk', 306: 'norm_4_rellinering_nk', 307: 'norm_4_relxilldgrad_nk', 308: 'norm_4_relxilldisk_nk', 309: 'norm_4_relxillNS', 310: 'norm_4_relxillD_nk', 311: 'norm_4_relxillion_nk', 312: 'norm_4_relxillionCp_nk', 313: 'norm_4_relxilllpion_nk', 314: 'norm_4_relxilllpionCp_nk', 315: 'norm_4_relxillring_nkxillver', 316: 'norm_4_xillverCp', 317: 'norm_4_xillverD', 318: 'norm_4_xillverNS', 319: 'factor_1', 320: 'factor_2', 321: 'factor_3', 322: 'factor_4', 323: 'dGamma_1', 324: 'dGamma_2', 325: 'dGamma_3', 326: 'dGamma_4', 327: 'crabcorNorm', 328: 'crabcorNorm_1', 329: 'crabcorNorm_2', 330: 'crabcorNorm_3', 331: 'crabcorNorm_4'}\n",
      "dict2:\n",
      "{'MaxTau': 0, 'nH': 1, 'nH_2': 2, 'Tin': 3, 'Tin_1': 4, 'Tin_2': 5, 'Tin_3': 6, 'Tin_4': 7, 'norm_diskbb': 8, 'norm_1_diskbb': 9, 'norm_2_diskbb': 10, 'norm_3_diskbb': 11, 'Mbh': 12, 'Mdd': 13, 'Dbh': 14, 'FracSctr': 15, 'FracSctr_1': 16, 'FracSctr_2': 17, 'FracSctr_3': 18, 'FracSctr_4': 19, 'norm_cutoffpl': 20, 'kT_bb': 21, 'norm_nthComp': 22, 'norm_1_nthComp': 23, 'norm_2_nthComp': 24, 'norm_3_nthComp': 25, 'norm_4_nthComp': 26, 'T0': 27, 'kT': 28, 'norm_compTT': 29, 'cov_frac': 30, 'PhoIndex': 31, 'PhoIndex_1': 32, 'PhoIndex_2': 33, 'PhoIndex_3': 34, 'PhoIndex_4': 35, 'Gamma_tau': 36, 'Gamma': 37, 'Gamma_1': 38, 'Gamma_2': 39, 'Gamma_3': 40, 'Gamma_4': 41, 'gamma': 42, 'kT_e': 43, 'kTe': 44, 'Ecut': 45, 'E_cut': 46, 'HighECut': 47, 'HighECut_2': 48, 'HighECut_3': 49, 'HighECut_4': 50, 'h': 51, 'Index1': 52, 'Index2': 53, 'Index3': 54, 'Rbr': 55, 'Rbr1': 56, 'Rbr2': 57, 'Rin': 58, 'a': 59, 'Incl': 60, 'i': 61, 'Afe': 62, 'xi_index': 63, 'refl_frac': 64, 'logN': 65, 'LineE': 66, 'LineE_2': 67, 'LineE_3': 68, 'LineE_4': 69, 'norm_gaussian': 70, 'norm_2_gaussian': 71, 'norm_3_gaussian': 72, 'norm_4_gaussian': 73, 'Sigma': 74, 'Sigma_2': 75, 'Sigma_3': 76, 'Sigma_4': 77, 'Xpos': 78, 'logxi_relconv': 79, 'logxi_relconv_lp': 80, 'logxi_relxill': 81, 'logxi_relxillCp': 82, 'logxi_relxill_nk': 83, 'logxi_relxillCp_nk': 84, 'logxi_relxill_nk2': 85, 'logxi_relxilllp': 86, 'logxi_relxilllpCp': 87, 'logxi_relxilllp_nk': 88, 'logxi_relxilllpCp_nk': 89, 'logxi_relxilllpD_nk': 90, 'logxi_relline': 91, 'logxi_relline_nk': 92, 'logxi_rellinedisk_nk': 93, 'logxi_relline_lp': 94, 'logxi_rellinelp_nk': 95, 'logxi_rellinering_nk': 96, 'logxi_relxilldgrad_nk': 97, 'logxi_relxilldisk_nk': 98, 'logxi_relxillNS': 99, 'logxi_relxillD_nk': 100, 'logxi_relxillion_nk': 101, 'logxi_relxillionCp_nk': 102, 'logxi_relxilllpion_nk': 103, 'logxi_relxilllpionCp_nk': 104, 'logxi_relxillring_nkxillver': 105, 'logxi_xillverCp': 106, 'logxi_xillverD': 107, 'logxi_xillverNS': 108, 'logxi_2_relconv': 109, 'logxi_2_relconv_lp': 110, 'logxi_2_relxill': 111, 'logxi_2_relxillCp': 112, 'logxi_2_relxill_nk': 113, 'logxi_2_relxillCp_nk': 114, 'logxi_2_relxill_nk2': 115, 'logxi_2_relxilllp': 116, 'logxi_2_relxilllpCp': 117, 'logxi_2_relxilllp_nk': 118, 'logxi_2_relxilllpCp_nk': 119, 'logxi_2_relxilllpD_nk': 120, 'logxi_2_relline': 121, 'logxi_2_relline_nk': 122, 'logxi_2_rellinedisk_nk': 123, 'logxi_2_relline_lp': 124, 'logxi_2_rellinelp_nk': 125, 'logxi_2_rellinering_nk': 126, 'logxi_2_relxilldgrad_nk': 127, 'logxi_2_relxilldisk_nk': 128, 'logxi_2_relxillNS': 129, 'logxi_2_relxillD_nk': 130, 'logxi_2_relxillion_nk': 131, 'logxi_2_relxillionCp_nk': 132, 'logxi_2_relxilllpion_nk': 133, 'logxi_2_relxilllpionCp_nk': 134, 'logxi_2_relxillring_nkxillver': 135, 'logxi_2_xillverCp': 136, 'logxi_2_xillverD': 137, 'logxi_2_xillverNS': 138, 'logxi_3_relconv': 139, 'logxi_3_relconv_lp': 140, 'logxi_3_relxill': 141, 'logxi_3_relxillCp': 142, 'logxi_3_relxill_nk': 143, 'logxi_3_relxillCp_nk': 144, 'logxi_3_relxill_nk2': 145, 'logxi_3_relxilllp': 146, 'logxi_3_relxilllpCp': 147, 'logxi_3_relxilllp_nk': 148, 'logxi_3_relxilllpCp_nk': 149, 'logxi_3_relxilllpD_nk': 150, 'logxi_3_relline': 151, 'logxi_3_relline_nk': 152, 'logxi_3_rellinedisk_nk': 153, 'logxi_3_relline_lp': 154, 'logxi_3_rellinelp_nk': 155, 'logxi_3_rellinering_nk': 156, 'logxi_3_relxilldgrad_nk': 157, 'logxi_3_relxilldisk_nk': 158, 'logxi_3_relxillNS': 159, 'logxi_3_relxillD_nk': 160, 'logxi_3_relxillion_nk': 161, 'logxi_3_relxillionCp_nk': 162, 'logxi_3_relxilllpion_nk': 163, 'logxi_3_relxilllpionCp_nk': 164, 'logxi_3_relxillring_nkxillver': 165, 'logxi_3_xillverCp': 166, 'logxi_3_xillverD': 167, 'logxi_3_xillverNS': 168, 'logxi_4_relconv': 169, 'logxi_4_relconv_lp': 170, 'logxi_4_relxill': 171, 'logxi_4_relxillCp': 172, 'logxi_4_relxill_nk': 173, 'logxi_4_relxillCp_nk': 174, 'logxi_4_relxill_nk2': 175, 'logxi_4_relxilllp': 176, 'logxi_4_relxilllpCp': 177, 'logxi_4_relxilllp_nk': 178, 'logxi_4_relxilllpCp_nk': 179, 'logxi_4_relxilllpD_nk': 180, 'logxi_4_relline': 181, 'logxi_4_relline_nk': 182, 'logxi_4_rellinedisk_nk': 183, 'logxi_4_relline_lp': 184, 'logxi_4_rellinelp_nk': 185, 'logxi_4_rellinering_nk': 186, 'logxi_4_relxilldgrad_nk': 187, 'logxi_4_relxilldisk_nk': 188, 'logxi_4_relxillNS': 189, 'logxi_4_relxillD_nk': 190, 'logxi_4_relxillion_nk': 191, 'logxi_4_relxillionCp_nk': 192, 'logxi_4_relxilllpion_nk': 193, 'logxi_4_relxilllpionCp_nk': 194, 'logxi_4_relxillring_nkxillver': 195, 'logxi_4_xillverCp': 196, 'logxi_4_xillverD': 197, 'logxi_4_xillverNS': 198, 'norm_relconv': 199, 'norm_relconv_lp': 200, 'norm_relxill': 201, 'norm_relxillCp': 202, 'norm_relxill_nk': 203, 'norm_relxillCp_nk': 204, 'norm_relxill_nk2': 205, 'norm_relxilllp': 206, 'norm_relxilllpCp': 207, 'norm_relxilllp_nk': 208, 'norm_relxilllpCp_nk': 209, 'norm_relxilllpD_nk': 210, 'norm_relline': 211, 'norm_relline_nk': 212, 'norm_rellinedisk_nk': 213, 'norm_relline_lp': 214, 'norm_rellinelp_nk': 215, 'norm_rellinering_nk': 216, 'norm_relxilldgrad_nk': 217, 'norm_relxilldisk_nk': 218, 'norm_relxillNS': 219, 'norm_relxillD_nk': 220, 'norm_relxillion_nk': 221, 'norm_relxillionCp_nk': 222, 'norm_relxilllpion_nk': 223, 'norm_relxilllpionCp_nk': 224, 'norm_relxillring_nkxillver': 225, 'norm_xillverCp': 226, 'norm_xillverD': 227, 'norm_xillverNS': 228, 'norm_2_relconv': 229, 'norm_2_relconv_lp': 230, 'norm_2_relxill': 231, 'norm_2_relxillCp': 232, 'norm_2_relxill_nk': 233, 'norm_2_relxillCp_nk': 234, 'norm_2_relxill_nk2': 235, 'norm_2_relxilllp': 236, 'norm_2_relxilllpCp': 237, 'norm_2_relxilllp_nk': 238, 'norm_2_relxilllpCp_nk': 239, 'norm_2_relxilllpD_nk': 240, 'norm_2_relline': 241, 'norm_2_relline_nk': 242, 'norm_2_rellinedisk_nk': 243, 'norm_2_relline_lp': 244, 'norm_2_rellinelp_nk': 245, 'norm_2_rellinering_nk': 246, 'norm_2_relxilldgrad_nk': 247, 'norm_2_relxilldisk_nk': 248, 'norm_2_relxillNS': 249, 'norm_2_relxillD_nk': 250, 'norm_2_relxillion_nk': 251, 'norm_2_relxillionCp_nk': 252, 'norm_2_relxilllpion_nk': 253, 'norm_2_relxilllpionCp_nk': 254, 'norm_2_relxillring_nkxillver': 255, 'norm_2_xillverCp': 256, 'norm_2_xillverD': 257, 'norm_2_xillverNS': 258, 'norm_3_relconv': 259, 'norm_3_relconv_lp': 260, 'norm_3_relxill': 261, 'norm_3_relxillCp': 262, 'norm_3_relxill_nk': 263, 'norm_3_relxillCp_nk': 264, 'norm_3_relxill_nk2': 265, 'norm_3_relxilllp': 266, 'norm_3_relxilllpCp': 267, 'norm_3_relxilllp_nk': 268, 'norm_3_relxilllpCp_nk': 269, 'norm_3_relxilllpD_nk': 270, 'norm_3_relline': 271, 'norm_3_relline_nk': 272, 'norm_3_rellinedisk_nk': 273, 'norm_3_relline_lp': 274, 'norm_3_rellinelp_nk': 275, 'norm_3_rellinering_nk': 276, 'norm_3_relxilldgrad_nk': 277, 'norm_3_relxilldisk_nk': 278, 'norm_3_relxillNS': 279, 'norm_3_relxillD_nk': 280, 'norm_3_relxillion_nk': 281, 'norm_3_relxillionCp_nk': 282, 'norm_3_relxilllpion_nk': 283, 'norm_3_relxilllpionCp_nk': 284, 'norm_3_relxillring_nkxillver': 285, 'norm_3_xillverCp': 286, 'norm_3_xillverD': 287, 'norm_3_xillverNS': 288, 'norm_4_relconv': 289, 'norm_4_relconv_lp': 290, 'norm_4_relxill': 291, 'norm_4_relxillCp': 292, 'norm_4_relxill_nk': 293, 'norm_4_relxillCp_nk': 294, 'norm_4_relxill_nk2': 295, 'norm_4_relxilllp': 296, 'norm_4_relxilllpCp': 297, 'norm_4_relxilllp_nk': 298, 'norm_4_relxilllpCp_nk': 299, 'norm_4_relxilllpD_nk': 300, 'norm_4_relline': 301, 'norm_4_relline_nk': 302, 'norm_4_rellinedisk_nk': 303, 'norm_4_relline_lp': 304, 'norm_4_rellinelp_nk': 305, 'norm_4_rellinering_nk': 306, 'norm_4_relxilldgrad_nk': 307, 'norm_4_relxilldisk_nk': 308, 'norm_4_relxillNS': 309, 'norm_4_relxillD_nk': 310, 'norm_4_relxillion_nk': 311, 'norm_4_relxillionCp_nk': 312, 'norm_4_relxilllpion_nk': 313, 'norm_4_relxilllpionCp_nk': 314, 'norm_4_relxillring_nkxillver': 315, 'norm_4_xillverCp': 316, 'norm_4_xillverD': 317, 'norm_4_xillverNS': 318, 'factor_1': 319, 'factor_2': 320, 'factor_3': 321, 'factor_4': 322, 'dGamma_1': 323, 'dGamma_2': 324, 'dGamma_3': 325, 'dGamma_4': 326, 'crabcorNorm': 327, 'crabcorNorm_1': 328, 'crabcorNorm_2': 329, 'crabcorNorm_3': 330, 'crabcorNorm_4': 331}\n",
      "key_temp_1:\n",
      "[8, 37, 329, 0, 1, 222, 330, 52, 63, 62, 53, 56, 43, 60, 59, 78, 325, 22, 102, 15, 3]\n",
      "keys:\n",
      "['MaxTau', 'nH', 'Tin', 'norm_diskbb', 'FracSctr', 'norm_nthComp', 'Gamma', 'kT_e', 'Index1', 'Index2', 'Rbr1', 'a', 'Incl', 'Afe', 'xi_index', 'Xpos', 'logxi_relxillionCp_nk', 'norm_relxillionCp_nk', 'dGamma_3', 'crabcorNorm_2', 'crabcorNorm_3']\n",
      "elements: \n",
      "[{'MaxTau': '$0.095_{-0.021}^{+0.028}$', 'nH': '$6.33_{-0.05}^{+0.1}$', 'Tin': '$0.192_{-0.011}^{+0.004}$', 'norm_diskbb': '$6.2_{-1.8}^{+2.7}\\\\times10^{5}$', 'Gamma': '$2.052_{-0.004}^{+0.022}$', 'kT_e': '$38.0_{-1.1}^{+1.7}$', 'norm_nthComp': '$1.935_{-0.012}^{+0.12}$', 'Index1': '$10.0_{-1.4}^{+P}$', 'Index2': '$0.46_{-0.07}^{+0.06}$', 'Rbr1': '$5.59_{-0.21}^{+0.19}$', 'a': '$0.9911_{-0.0025}^{+0.0013}$', 'Incl': '$75.9_{-0.9}^{+0.7}$', 'logxi_relxillionCp_nk': '$3.15_{-0.04}^{+0.08}$', 'Afe': '$1.4_{-0.4}^{+0.1}$', 'xi_index': '$0.179_{-0.028}^{+0.03}$', 'norm_relxillionCp_nk': '$0.0046_{-0.0002}^{+0.0004}$', 'crabcorNorm_2': '$1.0142_{-0.0014}^{+0.0014}$', 'dGamma_3': '$-0.172_{-0.018}^{+0.013}$', 'crabcorNorm_3': '$0.745_{-0.016}^{+0.013}$'}, {'MaxTau': '$0.098_{-0.019}^{+0.014}$', 'Xpos': '$1.0_{-P}^{+P}$', 'nH': '$6.492_{-0.016}^{+0.12}$', 'Gamma': '$2.097_{-0.008}^{+0.019}$', 'FracSctr': '$0.23_{-0.07}^{+0.05}$', 'kT_e': '$43.3_{-2.3}^{+2.3}$', 'Tin': '$0.202_{-0.008}^{+0.005}$', 'norm_diskbb': '$7.52_{-0.07}^{+5}\\\\times10^{5}$', 'Index1': '$10.0_{-1.9}^{+P}$', 'Index2': '$0.50_{-0.09}^{+0.07}$', 'Rbr1': '$5.45_{-0.18}^{+1.4}$', 'a': '$0.9912_{-0.003}^{+0.0008}$', 'Incl': '$75.9_{-2.2}^{+0.8}$', 'logxi_relxillionCp_nk': '$3.26_{-0.2}^{+0.04}$', 'Afe': '$0.899_{-0.03}^{+0.018}$', 'xi_index': '$0.196_{-0.027}^{+0.03}$', 'norm_relxillionCp_nk': '$0.0073_{-0.0006}^{+0.0004}$', 'crabcorNorm_2': '$1.0142_{-0.0014}^{+0.0014}$', 'dGamma_3': '$-0.171_{-0.021}^{+0.01}$', 'crabcorNorm_3': '$0.746_{-0.024}^{+0.012}$'}, {'MaxTau': '$0.118_{-0.022}^{+0.023}$', 'Xpos': '$1.00_{-0.04}^{+P}$', 'nH': '$5.76_{-0.13}^{+0.12}$', 'Tin': '$0.42_{-0.08}^{+0.05}$', 'norm_diskbb': '$1124_{-459}^{+1534}$', 'Gamma': '$1.876_{-0.008}^{+0.009}$', 'kT_e': '$36.1_{-1.1}^{+2.0}$', 'norm_nthComp': '$0.44_{-0.08}^{+0.05}$', 'Index1': '$10.0_{-0.8}^{+P}$', 'Index2': '$1.50_{-0.14}^{+0.07}$', 'Rbr1': '$4.3_{-0.3}^{+1.9}$', 'a': '$0.981_{-0.013}^{+0.004}$', 'Incl': '$68.8_{-0.6}^{+0.9}$', 'logxi_relxillionCp_nk': '$4.70_{-0.06}^{+P}$', 'Afe': '$7.1_{-1.4}^{+1.3}$', 'xi_index': '$1.3_{-0.7}^{+0.5}$', 'norm_relxillionCp_nk': '$0.0065_{-0.0006}^{+0.0006}$', 'crabcorNorm_2': '$1.0142_{-0.0015}^{+0.0015}$', 'dGamma_3': '$-0.153_{-0.018}^{+0.019}$', 'crabcorNorm_3': '$0.771_{-0.025}^{+0.022}$'}, {'MaxTau': '$0.112_{-0.023}^{+0.025}$', 'Xpos': '$1.0_{-P}^{+P}$', 'nH': '$5.80_{-0.2}^{+0.15}$', 'Gamma': '$1.910_{-0.009}^{+0.04}$', 'FracSctr': '$0.15_{-0.04}^{+0.04}$', 'kT_e': '$37.2_{-7}^{+5}$', 'Tin': '$0.42_{-0.1}^{+0.05}$', 'norm_diskbb': '$1348_{-1001}^{+2374}$', 'Index1': '$10.0_{-0.5}^{+P}$', 'Index2': '$1.21_{-0.15}^{+0.4}$', 'Rbr1': '$5.15_{-0.6}^{+0.18}$', 'a': '$0.9764_{-0.016}^{+0.0007}$', 'Incl': '$68.35_{-0.25}^{+1.5}$', 'logxi_relxillionCp_nk': '$4.7_{-0.4}^{+P}$', 'Afe': '$5.84_{-2.7}^{+0.12}$', 'xi_index': '$1.2_{-0.4}^{+0.9}$', 'norm_relxillionCp_nk': '$0.00119_{-5.2e-05}^{+1.9e-05}$', 'crabcorNorm_2': '$1.0142_{-0.0014}^{+0.0015}$', 'dGamma_3': '$-0.148_{-0.02}^{+0.019}$', 'crabcorNorm_3': '$0.779_{-0.024}^{+0.023}$'}]\n"
     ]
    }
   ],
   "source": [
    "# type your txt files list:\n",
    "# infiles = ['relionCp-nk_best-fit.txt','relionCp-nk_q2-3_best-fit.txt','relionCp-nk+xillcp_logxi-0_best-fit.txt',\n",
    "#            'simp_disk+relionCp-nk_q2-free_best-fit.txt','mo_2B-1.txt','simp_disk+relionCp-nk_+xillcp_q2-free_best-fit.txt']\n",
    "# model_name = ['1A','1B','1C','2A','2B','2C']\n",
    "infiles = ['mo1_bes-fit.txt','mo2_best-fit.txt','mo1_local_best-fit.txt','mo2_local_best-fit.txt']\n",
    "model_name = ['mo1','mo2','mo1_local','mo2_local']\n",
    "\n",
    "print_final_latex_code(infiles,model_name,debug=True,output_filename='latex_table_output.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0892ec632cc5bc01ba49379c22c0b312adff907935143a2b003e64b1c0e2b2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
