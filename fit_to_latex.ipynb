{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this notebook, you need to create a txt file which contains \n",
    "# the output results of xspec commands:{show free,show fit,error},\n",
    "# and you should paste the 'error' results of *all* parameters.\n",
    "\n",
    "# based on XSPEC version: 12.12.1, Not compatible with older versions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import imp\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "#relxill_v.2.0\n",
    "relxill_family = ['relconv','relconv_lp'\n",
    "                  'relxill','relxillCp',\n",
    "                  'relxilllp','relxilllpCp',\n",
    "                  'relline','relline_lp',\n",
    "                  'relxillNS',\n",
    "                  'xillver','xillverCp',\n",
    "                  'xillverD',\n",
    "                  'xillverNS']\n",
    "#relxill_nk_v.1.6.3\n",
    "relxill_nk_family = ['relxill_nk','relxillCp_nk',\n",
    "                     'relxill_nk2',\n",
    "                     'relxillD_nk',\n",
    "                     'relline_nk',\n",
    "                     'rellinedisk_nk',\n",
    "                     'rellinelp_nk',\n",
    "                     'rellinering_nk',\n",
    "                     'relxilllp_nk','relxilllpCp_nk',\n",
    "                     'relxilllpD_nk'\n",
    "                     'relxilldgrad_nk',\n",
    "                     'relxilldisk_nk',\n",
    "                     'relxillion_nk','relxillionCp_nk',\n",
    "                     'relxilllpion_nk','relxilllpionCp_nk',\n",
    "                     'relxillring_nk']\n",
    "#combine\n",
    "rel_family = ['relconv','relconv_lp',\n",
    "              'relxill','relxillCp','relxill_nk','relxillCp_nk','relxill_nk2',\n",
    "              'relxilllp','relxilllpCp','relxilllp_nk','relxilllpCp_nk',\n",
    "              'relxilllpD_nk',\n",
    "              'relline','relline_nk','rellinedisk_nk',\n",
    "              'relline_lp','rellinelp_nk',\n",
    "              'rellinering_nk',\n",
    "              'relxilldgrad_nk',\n",
    "              'relxilldisk_nk',\n",
    "              'relxillNS',\n",
    "              'relxillD_nk',\n",
    "              'relxillion_nk','relxillionCp_nk',\n",
    "              'relxilllpion_nk','relxilllpionCp_nk',\n",
    "              'relxillring_nk'\n",
    "              'xillver','xillverCp',\n",
    "              'xillverD',\n",
    "              'xillverNS']\n",
    "\n",
    "def add_something(strs:list,add:str):\n",
    "    new_strs = []\n",
    "    for str in strs:\n",
    "        new_strs.append(add+'_'+str)\n",
    "    return new_strs\n",
    "#norm    \n",
    "norm_rel = add_something(rel_family,'norm')\n",
    "#logxi\n",
    "logxi_xill = add_something(rel_family,'logxi')\n",
    "# print(logxi_xill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function may need to check or modify:\n",
    "#you need check if all the parameters strings are in the *parameters lib* in the function \"sort_parameters\"\n",
    "#if not, you should add them to \"sort_parameters\" and their respective latex strings in the function \"get_latex_of_parameters\"\n",
    "def sort_parameters(key_origin):\n",
    "    #在此函数中设定表格中参数的顺序，根据需求修改\n",
    "    #创建一个字典，键是序列keys里的元素，值是对应的latex字符串\n",
    "    #需根据实际情况进行扩充或修改。\n",
    "    parameter_lib = ['nH',#tbabs\n",
    "                     'nH_2',#tbabs_2\n",
    "                     'Tin','norm_diskbb',#diskbb\n",
    "                     'Mbh','Mdd','Dbh',#kerrbb\n",
    "                     'FracSctr',#simplcutx\n",
    "                     'norm_cutoffpl','kT_bb','norm_nthComp',#nthcomp or cutoffpl\n",
    "                     'T0','kT','norm_compTT',#compTT\n",
    "                     'cov_frac',#thcomp\n",
    "                     'Gamma_tau','Gamma','gamma','kT_e','kTe','Ecut','E_cut',#power-law component\n",
    "                     'h',#lamppost corona\n",
    "                     'Index1','Index2','Index3','Rbr','Rbr1','Rbr2',#emission profile\n",
    "                     'Rin',\n",
    "                     'a',#black hole\n",
    "                     'Incl','i',#accretion disk\n",
    "                     'Afe',#abundance\n",
    "                     'xi_index',#reflection\n",
    "                     'refl_frac',\n",
    "                     'logN',\n",
    "                     ] + logxi_xill + norm_rel + ['factor_1','factor_2','factor_3','factor_4'] \n",
    "    a = range(len(parameter_lib))\n",
    "    dict1 = dict(zip(a,parameter_lib))\n",
    "    # print('dict1:')\n",
    "    # print(dict1)\n",
    "    dict2 = dict(zip(parameter_lib,a))\n",
    "    # print('dict2:')\n",
    "    # print(dict2)\n",
    "   \n",
    "    key_temp_1 = []\n",
    "    keys = []\n",
    "    # print('key_origin:')\n",
    "    # print(key_origin)\n",
    "    for i in key_origin:\n",
    "        key_temp_1.append(dict2.get(i))\n",
    "    for a in key_temp_1:\n",
    "        if a == 'None':\n",
    "            print(\"you are missing some parameters in 'parameters_lib', please check it in function 'sort_parameters'\")\n",
    "    # print('key_temp_1:')\n",
    "    # print(key_temp_1)\n",
    "\n",
    "    key_temp_2 = sorted(key_temp_1)  \n",
    "    for j in key_temp_2:\n",
    "        keys.append(dict1.get(j))\n",
    "    # print(keys)  \n",
    "    return keys\n",
    "\n",
    "def get_latex_of_parameters(keys):\n",
    "    #we need to call another function to determine the output latex for some parameters\n",
    "    #such as: Index1,2, Rbr(nk or not nk)\n",
    "    #factor:output without the instrument names, you should fill it by yourself.\n",
    "    number = len(keys)\n",
    "    keys_latex = [None]*number\n",
    "    for i in range(number):\n",
    "        #tbabs\n",
    "        if keys[i] in ['nH','nH_2']:\n",
    "            keys_latex[i] = '$N_{\\\\rm H}$ [\\\\(10^{22}\\\\) cm\\\\(^{-2}\\\\)]'\n",
    "        #diskbb\n",
    "        if keys[i] == 'Tin':\n",
    "            keys_latex[i] = '$T_{\\\\rm in}$'\n",
    "        #kerrbb\n",
    "        if keys[i] == 'Mbh':\n",
    "            keys_latex[i] = '$M$'\n",
    "        if keys[i] == 'Mdd':\n",
    "            keys_latex[i] = '$\\dot M$'\n",
    "        if keys[i] == 'Dbh':\n",
    "            keys_latex[i] = '$D$'\n",
    "        #simplcutx\n",
    "        if keys[i] == 'FracSctr':\n",
    "            keys_latex[i] = '$f_{\\\\tt SC}$'\n",
    "        #nthcomp\n",
    "        if keys[i] == 'kT_bb':\n",
    "            keys_latex[i] = '$kT_{bb}$'\n",
    "        #compTT\n",
    "        if keys[i] == 'T0':\n",
    "            keys_latex[i] = '$T_{0}$'\n",
    "        if keys[i] == 'kT':\n",
    "            keys_latex[i] = '$T_{plasma}$'\n",
    "        #thcomp\n",
    "        if keys[i] == 'cov_frac':\n",
    "            keys_latex[i] = '$cov_{\\\\rm frac}$'\n",
    "        if keys[i] == 'Gamma_tau':\n",
    "            keys_latex[i] = '$\\\\Gamma_{\\\\tau}$'\n",
    "        #power-law component\n",
    "        if keys[i] in ['Gamma', 'gamma']:\n",
    "            keys_latex[i] = '$\\\\Gamma$'\n",
    "        if keys[i] in ['kT_e','kTe']:\n",
    "            keys_latex[i] = '$kT_{\\\\rm e}$ [keV]'\n",
    "        if keys[i] in ['E_cut','Ecut']:\n",
    "            keys_latex[i] = '$E_{\\\\rm cut}$'\n",
    "        #lamppost corona\n",
    "        if keys[i] == 'h':\n",
    "            keys_latex[i] = '$h$'\n",
    "        #emission profiles\n",
    "        if keys[i] == 'Index1':\n",
    "            keys_latex[i] = '$q_{\\\\rm in}$'\n",
    "        if keys[i] == 'Index2':\n",
    "            keys_latex[i] = '$q_{\\\\rm out}$ '\n",
    "        if keys[i] == 'Index3':\n",
    "            keys_latex[i] = '$q_{3}$'\n",
    "        if keys[i] == 'Rbr':\n",
    "            keys_latex[i] = '$R_{\\\\rm br}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr1':\n",
    "            keys_latex[i] = '$R_{\\\\rm br1}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr2':\n",
    "            keys_latex[i] = '$R_{\\\\rm br2}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rin':\n",
    "            keys_latex[i] = '$R_{\\\\rm in}$'\n",
    "        #black hole\n",
    "        if keys[i] == 'a':\n",
    "            keys_latex[i] = '$a_{*}$'\n",
    "        #accretion disk\n",
    "        if keys[i] in ['Incl','i']:\n",
    "            keys_latex[i] = '$i$ [deg]'\n",
    "        #abundance\n",
    "        if keys[i] == 'Afe':\n",
    "            keys_latex[i] = 'A$_{\\\\rm Fe}$'\n",
    "        #reflection\n",
    "        if keys[i] == 'xi_index':\n",
    "            keys_latex[i] = '$\\\\alpha_{\\\\xi}$' \n",
    "        if keys[i] == 'refl_frac':\n",
    "            keys_latex[i] = '$R_{\\\\rm f}$'\n",
    "        if keys[i] == 'logN':\n",
    "            keys_latex[i] = 'log${\\\\rm N}$'\n",
    "        #norm\n",
    "        if keys[i].split('_')[0] == 'norm':\n",
    "            keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[1] + '})'\n",
    "        #logxi\n",
    "        if keys[i].split('_')[0] == 'logxi':\n",
    "            keys_latex[i] = 'log${\\\\xi}$('+ keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "        #factor:output without the instrument names, you should fill it by yourself in latex.\n",
    "        if keys[i].split('_')[0] == 'factor':\n",
    "            keys_latex[i] = '$C_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "    par_latex = dict(zip(keys,keys_latex))\n",
    "    return par_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt file pre-treatment\n",
    "def do_something2multifiles(infiles:list):\n",
    "    for infile in infiles:\n",
    "        delete_hashtag_and_blank_line(infile)\n",
    "        add_index2par_single_file(infile)\n",
    "        delete_useless_str(infile)\n",
    "        mod_nk(infile)\n",
    "        i2incl(infile)\n",
    "        show_par2show_free(infile)\n",
    "    check_Rbr(infiles)\n",
    "        \n",
    "def delete_hashtag_and_blank_line(file): \n",
    "    # \"#\"and blank line should be removed first.\n",
    "    file_data = \"\"\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if '#' in line:\n",
    "                    line = line.replace('#','')\n",
    "                if line == '\\n':\n",
    "                    line = line.strip(\"\\n\")           \n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "\n",
    "def delete_useless_str(file):\n",
    "    # 请先保证文档没有空行。\n",
    "    file_data = \"\"   \n",
    "    str_delete = ['Apparent','Current','and','but','Suggest',\n",
    "                  'Error','***','caused','Parameter','***Warning:','Due','Suggest','pparent','Please']    \n",
    "    with open(file, \"r\") as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line.split() == []:\n",
    "                continue\n",
    "            if line.split()[0] not in str_delete:\n",
    "                file_data += line   \n",
    "    with open(file,\"w\",encoding=\"utf-8\") as output:\n",
    "        output.write(file_data) \n",
    "    \n",
    "def add_index2par_single_file(infile):\n",
    "    #example: factor -> factor_2; factor -> factor_3\n",
    "    #example: nH -> nH_2\n",
    "    file_data = \"\"\n",
    "    index = ''\n",
    "    with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if len(lines[i].split()) < 3:\n",
    "                continue\n",
    "            elif lines[i].split()[0] == 'Data' and lines[i].split()[2] != '1':\n",
    "                index = lines[i].split()[2]\n",
    "                factor = lines[i+1].split()[3]\n",
    "                if factor == 'factor':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('factor','factor'+'_'+index)\n",
    "                if len(lines[i+2].split()) > 3:\n",
    "                    nH = lines[i+2].split()[3]\n",
    "                    if nH == 'nH':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('nH','nH'+'_'+index)              \n",
    "        for line in lines:\n",
    "            file_data += line\n",
    "    with open(infile, \"w\", encoding=\"utf-8\") as f: \n",
    "        f.write(file_data)      \n",
    "\n",
    "def mod_nk(file):\n",
    "    #因为nk后缀会破坏按行切分\n",
    "    # 替换文件中的字符串,把rexill_nk的后缀nk去掉。这个函数对需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace('_nk','_nk ')\n",
    "            line = line.replace('relxilllpCp','relxilllpCp ')\n",
    "            file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "           \n",
    "def check_Rbr(files:list):\n",
    "    #first, make a judgement and decide whether to replace 'Rbr' with 'Rbr_1'\n",
    "    a = 0\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\" utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if 'Rbr_2' in line.split():\n",
    "                    a += 1\n",
    "    if a > 0:        \n",
    "        for file in files:\n",
    "        # 替换文件中的字符串,把Rbr替换为Rbr_1。这是因为我们需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "            file_data = \"\"\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if ('Rbr' in line) and ('Rbr1' not in line) and ('Rbr2' not in line):\n",
    "                        line = line.replace('Rbr','Rbr1')\n",
    "                    file_data += line\n",
    "            with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(file_data)\n",
    "                f.close()  \n",
    "def i2incl(file):\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) < 4:\n",
    "                file_data += line\n",
    "            else:\n",
    "                if line.split()[3] == 'i':\n",
    "                    line = line.replace('i','Incl')\n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)       \n",
    "def show_par2show_free(file):\n",
    "    #get error list\n",
    "    error_list = []\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) == 4:\n",
    "                if len(line.split()[-1].split(',')) == 2:\n",
    "                    error_list.append(line.split()[0])\n",
    "    #read show par and copy some fo them\n",
    "    file_data = \"\"\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'par' and line.split()[1] == 'comp':\n",
    "                    start_index = int(x[0]) + 2\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:               \n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'Fit':\n",
    "                    end_index = int(x[0]) - 1\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            copy = True\n",
    "            index = x[0]\n",
    "            line = x[1]\n",
    "            if index >= start_index and index <= end_index:\n",
    "                if len(line.split()) > 1:\n",
    "                    if line.split()[0] in error_list:\n",
    "                        copy = True\n",
    "                    else:\n",
    "                        copy = False        \n",
    "                else:\n",
    "                    copy = True\n",
    "            else:\n",
    "                copy = True     \n",
    "            if copy == True:\n",
    "                file_data += line\n",
    "    #write down the new file\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters values from the data\n",
    "def get_par_best_error(infile):\n",
    "    \n",
    "    index = []\n",
    "    parameter = []\n",
    "    best_fit = []\n",
    "    bound = []\n",
    "    data_group_index = ''\n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                if (line.split()[3] == 'norm' or line.split()[3] == 'logxi'):\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3] + \"_\" + line.split()[2])\n",
    "                    #example: 'norm' + '_' + 'nthcomp'\n",
    "                else:\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3])\n",
    "    parameters = dict(zip(index,parameter))\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                index.append(line.split()[0])\n",
    "                best_fit.append(line.split()[-3])\n",
    "    best = dict(zip(index,best_fit)) \n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>3:\n",
    "            if line.split()[-1][-1]==\")\":\n",
    "                if len(line.split()[-1].split(','))>1.1:\n",
    "                    index.append(line.split()[0])\n",
    "                    bound.append([line.split()[1], line.split()[2]])\n",
    "                    \n",
    "    bounds = dict(zip(index,bound))\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return parameters, best, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latex elements\n",
    "def get_latex_elements_single_file(infile):\n",
    "    import imp\n",
    "    import error2latex as el\n",
    "    imp.reload(el)\n",
    "    \n",
    "    parameter, best_fit, bounds = get_par_best_error(infile)\n",
    "    \n",
    "    #index = []\n",
    "    par = []\n",
    "    latex_c = []\n",
    "    \n",
    "    if len(best_fit)!=len(bounds):\n",
    "        print(\"Error: best-fit parameters do not match the number of uncertainties\")\n",
    "        print(f\"Number of free parameters: {len(best_fit)}, number of boundaries: {len(bounds)}\")\n",
    "    \n",
    "    for key in best_fit.keys():\n",
    "        name = parameter[key]\n",
    "        best = best_fit[key]\n",
    "        lower = bounds[key][0]\n",
    "        upper = bounds[key][1]\n",
    "        string, value_base, err_low_base, err_high_base = el.get_xspec_error(best, lower, upper) \n",
    "        \n",
    "        #index.append(key)\n",
    "        par.append(name)\n",
    "        latex_c.append(string)    \n",
    "        \n",
    "       # print(string)\n",
    "    #result = dict(zip(index,latex_c))\n",
    "    # print(par)\n",
    "    result = dict(zip(par,latex_c))\n",
    "    print('Hey! latex elements have been got from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_latex_elements_multiple_file(infiles):\n",
    "    number = len(infiles)\n",
    "    elements = [None]*number\n",
    "    for i in range(number):\n",
    "        elements[i] = get_latex_elements_single_file(infiles[i])\n",
    "    pars = []\n",
    "    for i in range(number):\n",
    "        pars = pars + list(elements[i].keys())\n",
    "    keys_origin = list(set(pars))\n",
    "#     print(keys_origin)\n",
    "    keys = sort_parameters(keys_origin)\n",
    "    \n",
    "    return elements, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics values and its latex code\n",
    "def get_chi_sq_and_AICc_single_file(infile):\n",
    "# based on XSPEC version: 12.12.1, not Not compatible with older versions! \n",
    "# because the xspec outputs of \"show fit\" are different in version: 12.12.1 \n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    index = ['chisq','dof','reduced_chisq','N-bin','N-par','AICc']\n",
    "    value = [None]*6\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.split()[0] == 'Test' and line.split()[-1] == 'bins.':\n",
    "            value[3] = int(line.split()[-2])\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4:\n",
    "            if line.split()[-1] == 'd.o.f.':\n",
    "                value[0] = float(line.split()[3])\n",
    "                value[1] = int(line.split()[-2])\n",
    "                value[2] = float(\"{:.5f}\".format(value[0] / value[1]))\n",
    "\n",
    "    value[4] = value[3] - value[1]\n",
    "    \n",
    "    value[5] = float(\"{:.2f}\".format(value[0] + 2*value[4] + 2*value[4]*(value[4]+1)/(value[3]-value[4]-1)))\n",
    "    \n",
    "    result = dict(zip(index,value))\n",
    "    \n",
    "#     print('got statistic from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_chi_sq_and_AICc_multiple_files(infiles):\n",
    "    \n",
    "    number = len(infiles)\n",
    "    chisq, dof, reduced_chisq, AICc = [None]*number, [None]*number, [None]*number, [None]*number\n",
    "    for i in range(number):\n",
    "        chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('chisq')\n",
    "        dof[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('dof')\n",
    "        reduced_chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('reduced_chisq')\n",
    "        AICc[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('AICc')\n",
    "\n",
    "    string = '$\\chi^2$ /dof'\n",
    "    \n",
    "    string_AICc = 'AICc'\n",
    "    \n",
    "    for n in range(number):\n",
    "        string = string + ' & ' +'\\\\tabincell{c}{' + str(chisq[n]) + '/' + str(dof[n]) + '=\\\\\\\\' + str(reduced_chisq[n]) + '}'\n",
    "        string_AICc = string_AICc + ' & ' + str(AICc[n])\n",
    "        \n",
    "    print('\\\\hline' + '\\n\\n' + string + '\\\\\\\\' + '\\n\\n' + string_AICc +  '\\\\\\\\' + '\\n\\n' + '\\\\hline' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally,print the full latex code\n",
    "def print_final_latex_code(infiles:list):\n",
    "    \n",
    "    do_something2multifiles(infiles)\n",
    "    \n",
    "    elements, keys = get_latex_elements_multiple_file(infiles)\n",
    "    #去掉多余的减号\n",
    "    for i in range(len(infiles)):\n",
    "        for key in elements[i].keys():\n",
    "            elements[i][key] = elements[i][key].replace('{--','{-')\n",
    "    # print('elements: ')\n",
    "    # print(elements)\n",
    "    # print('keys: ')\n",
    "    # print(keys)\n",
    "    \n",
    "    par_latex = get_latex_of_parameters(keys)\n",
    "    # print(par_latex)\n",
    "    \n",
    "    # newcommand reminder:\n",
    "    print(\"please copy this to the front of your .tex file in order to use commands:'tabincell':\\n\")\n",
    "    print(\"\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}\\n\")\n",
    "    \n",
    "    #resizebox or not\n",
    "    if len(infiles) > 5:\n",
    "        print('\\n'+'%please copy this line to the front of your .tex document in order to use \\\\tabincell: '+ '\\n'\n",
    "              +'\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}' + '\\n')\n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{bestfit}' + '\\n' + '\\\\resizebox{\\\\textwidth}{70mm}{' )\n",
    "    else:\n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{bestfit}' + '\\n')\n",
    "    #table\n",
    "    chart = '' \n",
    "    for i in range(len(infiles)):\n",
    "        chart += 'c'\n",
    "\n",
    "    print('\\\\begin{tabular}{l' + chart + '}'+ '\\n')\n",
    "    \n",
    "    print('\\\\hline' + '\\n')\n",
    "    \n",
    "    model = 'Model'\n",
    "    for i in range(len(infiles)):\n",
    "        model += (' & ' + 'Model ' + str(i+1))\n",
    "    \n",
    "    print(model + '\\\\\\\\' + '\\n')\n",
    "    \n",
    "    print('\\\\hline' + '\\n')\n",
    "    \n",
    "    for par in keys:\n",
    "        string = par_latex.get(par)\n",
    "        for n in range(len(infiles)):\n",
    "            if par in set(list(elements[n].keys())):\n",
    "#                 print(string)\n",
    "                string = string + ' & '+ elements[n][par]\n",
    "            else:\n",
    "                string = string + ' & ' + ' - '\n",
    "        print(string + '\\\\\\\\' + '\\n')\n",
    "\n",
    "    print_chi_sq_and_AICc_multiple_files(infiles)\n",
    "    \n",
    "    #print AICc\n",
    "    \n",
    "    if len(infiles) > 5:\n",
    "        print('\\\\end{tabular}' + '\\n' + '}' + '\\n' + '\\\\end{table*}')\n",
    "    else:\n",
    "        print('\\\\end{tabular}' + '\\n' + '\\n' + '\\\\end{table*}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diskbb+relCp_best-fit.txt', 'fit1.txt', 'fit2.txt', 'fit3.txt', 'fit4.txt', 'fit5.txt', 'fit6.txt', 'fit7.txt', 'fit8.txt', 'kerrbb+relCp_best-fit.txt', 'kerrbb+relCp_free_best-fit.txt', 'k_relxilllpcp_0.txt', 'k_relxilllpcp_1.txt', 'k_relxilllp_0.txt', 'k_relxilllp_1.txt', 'nu80001044002_relxillcp.txt', 'nu80001044002_thcomp+relxillcp.txt', 'nu80001044004_relxillcp.txt', 'nu80001044004_thcomp+relxillcp.txt', 'nu80001044006_relxillcp.txt', 'nu80001044006_thcomp+relxillcp.txt', 'nu80002040002_relxillcp.txt', 'nu80002040002_thcomp+relxillcp.txt', 'nu80002040004_relxillcp.txt', 'nu80002040004_thcomp+relxillcp.txt', 'nu80202012002_relxillcp.txt', 'nu80202012002_thcomp+relxillcp.txt', 'nu80202012004_relxillcp.txt', 'nu80202012004_thcomp+relxillcp.txt', 'nu80202012006_relxillcp.txt', 'nu80202012006_thcomp+relxillcp.txt', 'nu90401335002_relxillcp.txt', 'nu90401335002_thcomp+relxillcp.txt', 'relionCp-nk+xillcp_logxi-0_best-fit.txt', 'relionCp-nk+xillcp_logxi-free_best-fit.txt', 'relionCp-nk_best-fit_2662.txt', 'relionCp-nk_two-br_best-fit_2662.txt', 'simp_disk+relCp_best-fit.txt', 'test.txt']\n"
     ]
    }
   ],
   "source": [
    "#get txt_file list\n",
    "path = './'\n",
    "dirs = os.listdir(path)\n",
    "txt_files = []\n",
    "for name in dirs:\n",
    "    if name.split('.')[-1] == 'txt':\n",
    "        txt_files.append(name)\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! latex elements have been got from test.txt\n",
      "please copy this to the front of your .tex file in order to use commands:'tabincell':\n",
      "\n",
      "\\newcommand{\\tabincell}[2]{\\begin{tabular}{@{}#1@{}}#2\\end{tabular}}\n",
      "\n",
      "\\begin{table*}\n",
      "\\centering\n",
      "\\renewcommand\\arraystretch{1.5}\n",
      "\\caption{}\n",
      "\\label{bestfit}\n",
      "\n",
      "\\begin{tabular}{lc}\n",
      "\n",
      "\\hline\n",
      "\n",
      "Model & Model 1\\\\\n",
      "\n",
      "\\hline\n",
      "\n",
      "$N_{\\rm H}$ [\\(10^{22}\\) cm\\(^{-2}\\)] & $9.08_{-0.07}^{+0.05}$\\\\\n",
      "\n",
      "Norm({\\tt nthComp}) & $4.76_{-0.22}^{+0.12}$\\\\\n",
      "\n",
      "$\\Gamma$ & $2.442_{-0.011}^{+0.004}$\\\\\n",
      "\n",
      "$kT_{\\rm e}$ [keV] & $174_{-44}^{+40}$\\\\\n",
      "\n",
      "$q_{\\rm in}$ & $10.00_{-0.23}^{+P}$\\\\\n",
      "\n",
      "$q_{\\rm out}$  & $0.001_{-P}^{+0.08}$\\\\\n",
      "\n",
      "$R_{\\rm br1}$ [$R_{\\rm g}$] & $6.18_{-0.16}^{+0.25}$\\\\\n",
      "\n",
      "$a_{*}$ & $0.9933_{-0.001}^{+0.0005}$\\\\\n",
      "\n",
      "$i$ [deg] & $73.8_{-0.3}^{+0.5}$\\\\\n",
      "\n",
      "A$_{\\rm Fe}$ & $0.50_{-P}^{+0.04}$\\\\\n",
      "\n",
      "log${\\xi}$(relxillCp)[erg~cm~s$^{-1}$] & $2.701_{-0.04}^{+0.017}$\\\\\n",
      "\n",
      "Norm({\\tt relxillCp}) & $0.375_{-0.008}^{+0.015}$\\\\\n",
      "\n",
      "$C_{\\rm instrument2}$ & $1.850_{-0.01}^{+0.006}$\\\\\n",
      "\n",
      "\\hline\n",
      "\n",
      "$\\chi^2$ /dof & \\tabincell{c}{2335.37/2209=\\\\1.05721}\\\\\n",
      "\n",
      "AICc & 2361.53\\\\\n",
      "\n",
      "\\hline\n",
      "\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "#type your txt files list:\n",
    "infiles = ['test.txt']\n",
    "print_final_latex_code(infiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce48db18bd2ae58c3479d3117947fc8c8d37f44167a15f59ed7bf5528145b177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
