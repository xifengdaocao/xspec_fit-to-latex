{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this notebook, you need to create a txt file which contains \n",
    "# the output results of xspec commands:{show free,show fit,error},\n",
    "# and you should paste the 'error' results of *all* parameters.\n",
    "\n",
    "# based on XSPEC version: 12.12.1, Not compatible with older versions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import imp\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "#relxill_v.2.0\n",
    "relxill_family = ['relconv','relconv_lp'\n",
    "                  'relxill','relxillCp',\n",
    "                  'relxilllp','relxilllpCp',\n",
    "                  'relline','relline_lp',\n",
    "                  'relxillNS',\n",
    "                  'xillver','xillverCp',\n",
    "                  'xillverD',\n",
    "                  'xillverNS']\n",
    "#relxill_nk_v.1.6.3\n",
    "relxill_nk_family = ['relxill_nk','relxillCp_nk',\n",
    "                     'relxill_nk2',\n",
    "                     'relxillD_nk',\n",
    "                     'relline_nk',\n",
    "                     'rellinedisk_nk',\n",
    "                     'rellinelp_nk',\n",
    "                     'rellinering_nk',\n",
    "                     'relxilllp_nk','relxilllpCp_nk',\n",
    "                     'relxilllpD_nk'\n",
    "                     'relxilldgrad_nk',\n",
    "                     'relxilldisk_nk',\n",
    "                     'relxillion_nk','relxillionCp_nk',\n",
    "                     'relxilllpion_nk','relxilllpionCp_nk',\n",
    "                     'relxillring_nk']\n",
    "#combine\n",
    "rel_family = ['relconv','relconv_lp',\n",
    "              'relxill','relxillCp','relxill_nk','relxillCp_nk','relxill_nk2',\n",
    "              'relxilllp','relxilllpCp','relxilllp_nk','relxilllpCp_nk',\n",
    "              'relxilllpD_nk',\n",
    "              'relline','relline_nk','rellinedisk_nk',\n",
    "              'relline_lp','rellinelp_nk',\n",
    "              'rellinering_nk',\n",
    "              'relxilldgrad_nk',\n",
    "              'relxilldisk_nk',\n",
    "              'relxillNS',\n",
    "              'relxillD_nk',\n",
    "              'relxillion_nk','relxillionCp_nk',\n",
    "              'relxilllpion_nk','relxilllpionCp_nk',\n",
    "              'relxillring_nk'\n",
    "              'xillver','xillverCp',\n",
    "              'xillverD',\n",
    "              'xillverNS']\n",
    "\n",
    "def add_something(strs:list,add:str):\n",
    "    new_strs = []\n",
    "    for str in strs:\n",
    "        new_strs.append(add+'_'+str)\n",
    "    return new_strs\n",
    "#norm    \n",
    "norm_rel = add_something(rel_family,'norm')\n",
    "#logxi\n",
    "logxi_xill = add_something(rel_family,'logxi')\n",
    "# print(logxi_xill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = ['factor_1','factor_2','factor_3','factor_4']\n",
    "dGamma = ['dGamma_1','dGamma_2','dGamma_3','dGamma_4']\n",
    "crabcorNorm = ['crabcorNorm_1','crabcorNorm_2','crabcorNorm_3','crabcorNorm_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function may need to check or modify:\n",
    "#you need check if all the parameters strings are in the *parameters lib* in the function \"sort_parameters\"\n",
    "#if not, you should add them to \"sort_parameters\" and their respective latex strings in the function \"get_latex_of_parameters\"\n",
    "def sort_parameters(key_origin,debug=False):\n",
    "    #在此函数中设定表格中参数的顺序，根据需求修改\n",
    "    #创建一个字典，键是序列keys里的元素，值是对应的latex字符串\n",
    "    #需根据实际情况进行扩充或修改。\n",
    "    if debug == True:\n",
    "        print('key_origin:')\n",
    "        print(key_origin)\n",
    "    parameter_lib = ['MaxTau',#edge\n",
    "                     'nH',#tbabs\n",
    "                     'nH_2',#tbabs_2\n",
    "                     'Tin','Tin_1','Tin_2','Tin_3','Tin_4',\n",
    "                     'norm_diskbb',#diskbb\n",
    "                     'Mbh','Mdd','Dbh',#kerrbb\n",
    "                     'FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4',#simplcutx\n",
    "                     'norm_cutoffpl','kT_bb',#nthcomp or cutoffpl\n",
    "                     'norm_nthComp','norm_1_nthComp','norm_2_nthComp','norm_3_nthComp','norm_4_nthComp',\n",
    "                     'T0','kT','norm_compTT',#compTT\n",
    "                     'cov_frac',#thcomp\n",
    "                     'Gamma_tau','Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma','kT_e','kTe','Ecut','E_cut',#power-law component\n",
    "                     'h',#lamppost corona\n",
    "                     'Index1','Index2','Index3','Rbr','Rbr1','Rbr2',#emission profile\n",
    "                     'Rin',\n",
    "                     'a',#black hole\n",
    "                     'Incl','i',#accretion disk\n",
    "                     'Afe',#abundance\n",
    "                     'xi_index',#reflection\n",
    "                     'refl_frac',\n",
    "                     'logN',\n",
    "                     ] + logxi_xill + norm_rel + factor + dGamma + crabcorNorm\n",
    "    a = range(len(parameter_lib))\n",
    "    dict1 = dict(zip(a,parameter_lib))\n",
    "    if debug == True:\n",
    "        print('dict1:')\n",
    "        print(dict1)\n",
    "    dict2 = dict(zip(parameter_lib,a))\n",
    "    if debug == True:\n",
    "        print('dict2:')\n",
    "        print(dict2)\n",
    "    key_temp_1 = []\n",
    "    keys = []\n",
    "    for i in key_origin:\n",
    "        key_temp_1.append(dict2.get(i))\n",
    "    for a in key_temp_1:\n",
    "        if a == 'None':\n",
    "            print(\"you are missing some parameters in 'parameters_lib', please check it in function 'sort_parameters'\")\n",
    "    if debug == True:\n",
    "        print('key_temp_1:')\n",
    "        print(key_temp_1)\n",
    "    key_temp_2 = sorted(key_temp_1)  \n",
    "    for j in key_temp_2:\n",
    "        keys.append(dict1.get(j))\n",
    "    if debug == True:\n",
    "        print('keys:')\n",
    "        print(keys)  \n",
    "    return keys\n",
    "\n",
    "def get_latex_of_parameters(keys):\n",
    "    #we need to call another function to determine the output latex for some parameters\n",
    "    #such as: Index1,2, Rbr(nk or not nk)\n",
    "    #factor:output without the instrument names, you should fill it by yourself.\n",
    "    number = len(keys)\n",
    "    keys_latex = [None]*number\n",
    "    for i in range(number):\n",
    "        #edge\n",
    "        if keys[i] == 'MaxTau':\n",
    "            keys_latex[i] = '$\\\\tau_{\\\\tt max}$'\n",
    "        #tbabs\n",
    "        if keys[i] in ['nH','nH_2']:\n",
    "            keys_latex[i] = '$N_{\\\\rm H}$ [\\\\(10^{22}\\\\) cm\\\\(^{-2}\\\\)]'\n",
    "        #diskbb\n",
    "        if keys[i] in ['Tin','Tin_1','Tin_2','Tin_3','Tin_4']:\n",
    "            keys_latex[i] = '$T_{\\\\rm in}$'\n",
    "        #kerrbb\n",
    "        if keys[i] == 'Mbh':\n",
    "            keys_latex[i] = '$M$'\n",
    "        if keys[i] == 'Mdd':\n",
    "            keys_latex[i] = '$\\dot M$'\n",
    "        if keys[i] == 'Dbh':\n",
    "            keys_latex[i] = '$D$'\n",
    "        #simplcutx\n",
    "        if keys[i] in ['FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4','FracSctr_5']:\n",
    "            keys_latex[i] = '$f_{\\\\tt SC}$'\n",
    "        #nthcomp\n",
    "        if keys[i] == 'kT_bb':\n",
    "            keys_latex[i] = '$kT_{bb}$'\n",
    "        #compTT\n",
    "        if keys[i] == 'T0':\n",
    "            keys_latex[i] = '$T_{0}$'\n",
    "        if keys[i] == 'kT':\n",
    "            keys_latex[i] = '$T_{plasma}$'\n",
    "        #thcomp\n",
    "        if keys[i] == 'cov_frac':\n",
    "            keys_latex[i] = '$cov_{\\\\rm frac}$'\n",
    "        if keys[i] == 'Gamma_tau':\n",
    "            keys_latex[i] = '$\\\\Gamma_{\\\\tau}$'\n",
    "        #power-law component\n",
    "        if keys[i] in ['Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma']:\n",
    "            keys_latex[i] = '$\\\\Gamma$'\n",
    "        if keys[i] in ['kT_e','kTe']:\n",
    "            keys_latex[i] = '$kT_{\\\\rm e}$ [keV]'\n",
    "        if keys[i] in ['E_cut','Ecut']:\n",
    "            keys_latex[i] = '$E_{\\\\rm cut}$'\n",
    "        #lamppost corona\n",
    "        if keys[i] == 'h':\n",
    "            keys_latex[i] = '$h$'\n",
    "        #emission profiles\n",
    "        if keys[i] == 'Index1':\n",
    "            keys_latex[i] = '$q_{\\\\rm in}$'\n",
    "        if keys[i] == 'Index2':\n",
    "            keys_latex[i] = '$q_{\\\\rm out}$ '\n",
    "        if keys[i] == 'Index3':\n",
    "            keys_latex[i] = '$q_{3}$'\n",
    "        if keys[i] == 'Rbr':\n",
    "            keys_latex[i] = '$R_{\\\\rm br}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr1':\n",
    "            keys_latex[i] = '$R_{\\\\rm br1}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr2':\n",
    "            keys_latex[i] = '$R_{\\\\rm br2}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rin':\n",
    "            keys_latex[i] = '$R_{\\\\rm in}$'\n",
    "        #black hole\n",
    "        if keys[i] == 'a':\n",
    "            keys_latex[i] = '$a_{*}$'\n",
    "        #accretion disk\n",
    "        if keys[i] in ['Incl','i']:\n",
    "            keys_latex[i] = '$i$ [deg]'\n",
    "        #abundance\n",
    "        if keys[i] == 'Afe':\n",
    "            keys_latex[i] = 'A$_{\\\\rm Fe}$'\n",
    "        #reflection\n",
    "        if keys[i] == 'xi_index':\n",
    "            keys_latex[i] = '$\\\\alpha_{\\\\xi}$' \n",
    "        if keys[i] == 'refl_frac':\n",
    "            keys_latex[i] = '$R_{\\\\rm f}$'\n",
    "        if keys[i] == 'logN':\n",
    "            keys_latex[i] = 'log${\\\\rm N}$'\n",
    "        #norm\n",
    "        if keys[i].split('_')[0] == 'norm':\n",
    "            if len(keys[i].split('_')) == 2:\n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[1] + '})'\n",
    "            else: \n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[2] + keys[i].split('_')[1] + '})'\n",
    "        #logxi\n",
    "        if keys[i].split('_')[0] == 'logxi':\n",
    "            keys_latex[i] = 'log${\\\\xi}$('+ keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "        #factor:output without the instrument names, you should fill it by yourself in latex.\n",
    "        if keys[i].split('_')[0] == 'factor':\n",
    "            keys_latex[i] = '$C_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'dGamma':\n",
    "            keys_latex[i] = '$dGamma_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'crabcorNorm':\n",
    "            keys_latex[i] = '$crabcorNorm_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "    par_latex = dict(zip(keys,keys_latex))\n",
    "    return par_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt file pre-treatment\n",
    "def do_something2multifiles(infiles:list):\n",
    "    for infile in infiles:\n",
    "        delete_hashtag_and_blank_line(infile)\n",
    "        add_index2par_single_file(infile)\n",
    "        delete_useless_str(infile)\n",
    "        mod_nk(infile)\n",
    "        i2incl(infile)\n",
    "        show_par2show_free(infile)\n",
    "    check_Rbr(infiles)\n",
    "        \n",
    "def delete_hashtag_and_blank_line(file): \n",
    "    # \"#\"and blank line should be removed first.\n",
    "    file_data = \"\"\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if '#' in line:\n",
    "                    line = line.replace('#','')\n",
    "                if line == '\\n':\n",
    "                    line = line.strip(\"\\n\")           \n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "\n",
    "def delete_useless_str(file):\n",
    "    # 请先保证文档没有空行。\n",
    "    file_data = \"\"   \n",
    "    str_delete = ['Apparent','Current','and','but','Suggest',\n",
    "                  'Error','***','caused','Parameter','***Warning:','Due','Suggest','pparent','Please']    \n",
    "    with open(file, \"r\") as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line.split() == []:\n",
    "                continue\n",
    "            if line.split()[0] not in str_delete:\n",
    "                file_data += line   \n",
    "    with open(file,\"w\",encoding=\"utf-8\") as output:\n",
    "        output.write(file_data) \n",
    "    \n",
    "def add_index2par_single_file(infile):\n",
    "    #example: factor -> factor_2; factor -> factor_3\n",
    "    #example: nH -> nH_2\n",
    "    file_data = \"\"\n",
    "    index = ''\n",
    "    with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if len(lines[i].split()) < 3:\n",
    "                continue\n",
    "            elif lines[i].split()[0] == 'Data' and lines[i].split()[2] != '1':\n",
    "                #第零行:数据组标题\n",
    "                index = lines[i].split()[2]\n",
    "                #第一行\n",
    "                factor = lines[i+1].split()[3]\n",
    "                if factor == 'factor':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('factor','factor'+'_'+index)\n",
    "                if factor == 'dGamma':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('dGamma','dGamma'+'_'+index)\n",
    "                if factor == 'Tin':\n",
    "                    lines[i+1] = lines[i+1].replace('Tin','Tin'+'_'+index)\n",
    "                if factor == 'FracSctr':\n",
    "                    lines[i+1] = lines[i+1].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                #第二行\n",
    "                if len(lines[i+2].split()) > 3:\n",
    "                    factor2 = lines[i+2].split()[3]\n",
    "                    if factor2 == 'nH':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('nH','nH'+'_'+index)\n",
    "                    if factor2 == 'crabcorNorm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('crabcorNorm','crabcorNorm'+'_'+index)\n",
    "                    if factor2 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('norm','norm'+'_'+index)\n",
    "                    if factor2 == 'Tin':\n",
    "                        lines[i+2] = lines[i+2].replace('Tin','Tin'+'_'+index)\n",
    "                #第三行\n",
    "                if len(lines[i+3].split()) > 3:\n",
    "                    factor3 = lines[i+3].split()[3]\n",
    "                    if factor3 == 'Tin':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+3] = lines[i+3].replace('Tin','Tin'+'_'+index)\n",
    "                    if factor3 == 'FracSctr':\n",
    "                        lines[i+3] = lines[i+3].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                #第四行\n",
    "                if len(lines[i+4].split()) > 3:\n",
    "                    factor4 = lines[i+4].split()[3]\n",
    "                    if factor4 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+4] = lines[i+4].replace('norm','norm'+'_'+index)\n",
    "                    if factor4 == 'Tin':\n",
    "                        lines[i+4] = lines[i+4].replace('Tin','Tin'+'_'+index)  \n",
    "                    if factor4 == 'Gamma':\n",
    "                        lines[i+4] = lines[i+4].replace('Gamma','Gamma'+'_'+index)              \n",
    "        for line in lines:\n",
    "            file_data += line\n",
    "    with open(infile, \"w\", encoding=\"utf-8\") as f: \n",
    "        f.write(file_data)      \n",
    "\n",
    "def mod_nk(file):\n",
    "    #因为nk后缀会破坏按行切分\n",
    "    # 替换文件中的字符串,把rexill_nk的后缀nk去掉。这个函数对需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace('_nk','_nk ')\n",
    "            line = line.replace('relxilllpCp','relxilllpCp ')\n",
    "            file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "           \n",
    "def check_Rbr(files:list):\n",
    "    #first, make a judgement and decide whether to replace 'Rbr' with 'Rbr_1'\n",
    "    a = 0\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\" utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if 'Rbr_2' in line.split():\n",
    "                    a += 1\n",
    "    if a > 0:        \n",
    "        for file in files:\n",
    "        # 替换文件中的字符串,把Rbr替换为Rbr_1。这是因为我们需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "            file_data = \"\"\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if ('Rbr' in line) and ('Rbr1' not in line) and ('Rbr2' not in line):\n",
    "                        line = line.replace('Rbr','Rbr1')\n",
    "                    file_data += line\n",
    "            with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(file_data)\n",
    "                f.close()  \n",
    "def i2incl(file):\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) < 4:\n",
    "                file_data += line\n",
    "            else:\n",
    "                if line.split()[3] == 'i':\n",
    "                    line = line.replace('i','Incl')\n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)     \n",
    "          \n",
    "def show_par2show_free(file):\n",
    "    #get error list\n",
    "    error_list = []\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) == 4:\n",
    "                if len(line.split()[-1].split(',')) == 2:\n",
    "                    error_list.append(line.split()[0])\n",
    "    #read show par and copy some fo them\n",
    "    file_data = \"\"\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'par' and line.split()[1] == 'comp':\n",
    "                    start_index = int(x[0]) + 2\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:               \n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'Fit':\n",
    "                    end_index = int(x[0]) - 1\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            copy = True\n",
    "            index = x[0]\n",
    "            line = x[1]\n",
    "            if index >= start_index and index <= end_index:\n",
    "                if len(line.split()) > 1:\n",
    "                    if line.split()[0] == 'Data':\n",
    "                        copy = True\n",
    "                    elif line.split()[0] in error_list:\n",
    "                        copy = True\n",
    "                    else:\n",
    "                        copy = False        \n",
    "                else:\n",
    "                    copy = True\n",
    "            else:\n",
    "                copy = True     \n",
    "            if copy == True:\n",
    "                file_data += line\n",
    "    #write down the new file\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters values from the data\n",
    "def get_par_best_error(infile):\n",
    "    \n",
    "    index = []\n",
    "    parameter = []\n",
    "    best_fit = []\n",
    "    bound = []\n",
    "    data_group_index = ''\n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                if (line.split()[3] in ['norm','norm_1','norm_2','norm_3','norm_4'] or line.split()[3] == 'logxi'):\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3] + \"_\" + line.split()[2])\n",
    "                    #example: 'norm' + '_' + 'nthcomp'\n",
    "                else:\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3])\n",
    "    parameters = dict(zip(index,parameter))\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                index.append(line.split()[0])\n",
    "                best_fit.append(line.split()[-3])\n",
    "    best = dict(zip(index,best_fit)) \n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>3:\n",
    "            if line.split()[-1][-1]==\")\":\n",
    "                if len(line.split()[-1].split(','))>1.1:\n",
    "                    index.append(line.split()[0])\n",
    "                    bound.append([line.split()[1], line.split()[2]])\n",
    "                    \n",
    "    bounds = dict(zip(index,bound))\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return parameters, best, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latex elements\n",
    "def get_latex_elements_single_file(infile,debug=False):\n",
    "    import imp\n",
    "    import error2latex as el\n",
    "    imp.reload(el)\n",
    "    \n",
    "    parameter, best_fit, bounds = get_par_best_error(infile)\n",
    "    \n",
    "    #index = []\n",
    "    par = []\n",
    "    latex_c = []\n",
    "    \n",
    "    if len(best_fit)!=len(bounds):\n",
    "        print(\"Error: best-fit parameters do not match the number of uncertainties\")\n",
    "        print(f\"Number of free parameters: {len(best_fit)}, number of boundaries: {len(bounds)}\")\n",
    "    \n",
    "    for key in best_fit.keys():\n",
    "        name = parameter[key]\n",
    "        best = best_fit[key]\n",
    "        lower = bounds[key][0]\n",
    "        upper = bounds[key][1]\n",
    "        string, value_base, err_low_base, err_high_base = el.get_xspec_error(best, lower, upper) \n",
    "        \n",
    "        #index.append(key)\n",
    "        par.append(name)\n",
    "        latex_c.append(string)    \n",
    "        \n",
    "       # print(string)\n",
    "    #result = dict(zip(index,latex_c))\n",
    "    # print(par)\n",
    "    result = dict(zip(par,latex_c))\n",
    "    if debug == True:\n",
    "        print('Hey! latex elements have been got from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_latex_elements_multiple_file(infiles,debug=False):\n",
    "    number = len(infiles)\n",
    "    elements = [None]*number\n",
    "    for i in range(number):\n",
    "        if debug == False:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i])\n",
    "        else:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i],debug=True)\n",
    "    pars = []\n",
    "    \n",
    "    for i in range(number):\n",
    "        pars = pars + list(elements[i].keys())\n",
    "    keys_origin = list(set(pars))\n",
    "    \n",
    "    if debug == True:\n",
    "        keys = sort_parameters(keys_origin,debug=True)\n",
    "    else:\n",
    "        keys = sort_parameters(keys_origin)\n",
    "        \n",
    "    return elements, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics values and its latex code\n",
    "def get_chi_sq_and_AICc_single_file(infile):\n",
    "# based on XSPEC version: 12.12.1, not Not compatible with older versions! \n",
    "# because the xspec outputs of \"show fit\" are different in version: 12.12.1 \n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    index = ['chisq','dof','reduced_chisq','N-bin','N-par','AICc']\n",
    "    value = [None]*6\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.split()[0] == 'Test' and line.split()[-1] == 'bins.':\n",
    "            value[3] = int(line.split()[-2])\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4:\n",
    "            if line.split()[-1] == 'd.o.f.':\n",
    "                value[0] = float(line.split()[3])\n",
    "                value[1] = int(line.split()[-2])\n",
    "                value[2] = float(\"{:.5f}\".format(value[0] / value[1]))\n",
    "\n",
    "    value[4] = value[3] - value[1]\n",
    "    \n",
    "    value[5] = float(\"{:.2f}\".format(value[0] + 2*value[4] + 2*value[4]*(value[4]+1)/(value[3]-value[4]-1)))\n",
    "    \n",
    "    result = dict(zip(index,value))\n",
    "    \n",
    "#     print('got statistic from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_chi_sq_and_AICc_multiple_files(infiles, outfile):\n",
    "    \n",
    "    number = len(infiles)\n",
    "    chisq, dof, reduced_chisq, AICc = [None]*number, [None]*number, [None]*number, [None]*number\n",
    "    for i in range(number):\n",
    "        chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('chisq')\n",
    "        dof[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('dof')\n",
    "        reduced_chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('reduced_chisq')\n",
    "        AICc[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('AICc')\n",
    "\n",
    "    string = '$\\chi^2$ /dof'\n",
    "    \n",
    "    string_AICc = 'AICc'\n",
    "    \n",
    "    for n in range(number):\n",
    "        string = string + ' & ' +'\\\\tabincell{c}{' + str(chisq[n]) + '/' + str(dof[n]) + '=\\\\\\\\' + str(reduced_chisq[n]) + '}'\n",
    "        string_AICc = string_AICc + ' & ' + str(AICc[n])\n",
    "        \n",
    "    print('\\\\hline' + '\\n\\n' + string + '\\\\\\\\' + '\\n\\n' + string_AICc +  '\\\\\\\\' + '\\n\\n' + '\\\\hline' + '\\n', file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally,print the full latex code\n",
    "def print_final_latex_code(infiles:list,model_name:list,debug=False,output_filename='latex_table_output.txt'):\n",
    "    # Open the file for writing\n",
    "    output_file = open(output_filename, \"w\")\n",
    "        \n",
    "    do_something2multifiles(infiles)\n",
    "    if debug == True:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles,debug=True)\n",
    "    else:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles)\n",
    "    #去掉多余的减号\n",
    "    for i in range(len(infiles)):\n",
    "        for key in elements[i].keys():\n",
    "            elements[i][key] = elements[i][key].replace('{--','{-')\n",
    "    if debug == True:\n",
    "        print('elements: ')\n",
    "        print(elements)\n",
    "    \n",
    "    par_latex = get_latex_of_parameters(keys)\n",
    "    # print(par_latex)\n",
    "    \n",
    "    # newcommand reminder:\n",
    "    \n",
    "    print(\"please copy this to the front of your .tex file in order to use commands:'tabincell':\\n\", file=output_file)\n",
    "    print(\"\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}\\n\", file=output_file)\n",
    "    \n",
    "    print(\"###########################################################################################################################\", file=output_file)\n",
    "    \n",
    "    #resizebox or not\n",
    "    if len(infiles) > 5:\n",
    "        print('\\n'+'%please copy this line to the front of your .tex document in order to use \\\\tabincell: '+ '\\n'\n",
    "              +'\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}' + '\\n', file=output_file)\n",
    "        \n",
    "        print(\"###########################################################################################################################\", file=output_file)\n",
    "        \n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n' + '\\\\resizebox{\\\\textwidth}{70mm}{' , file=output_file)\n",
    "    else:\n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n', file=output_file)\n",
    "    #table\n",
    "    chart = '' \n",
    "    for i in range(len(infiles)):\n",
    "        chart += 'c'\n",
    "\n",
    "    print('\\\\begin{tabular}{l' + chart + '}'+ '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    model = 'Model'\n",
    "    for i in range(len(infiles)):\n",
    "        model += (' & ' + 'Model ' + model_name[i])\n",
    "    \n",
    "    print(model + '\\\\\\\\' + '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    for par in keys:\n",
    "        string = par_latex.get(par)\n",
    "        for n in range(len(infiles)):\n",
    "            if par in set(list(elements[n].keys())):\n",
    "    #                 print(string)\n",
    "                string = string + ' & '+ elements[n][par]\n",
    "            else:\n",
    "                string = string + ' & ' + ' - '\n",
    "        print(string + '\\\\\\\\' + '\\n', file=output_file)\n",
    "\n",
    "    print_chi_sq_and_AICc_multiple_files(infiles, output_file)\n",
    "    \n",
    "    #print AICc\n",
    "    \n",
    "    if len(infiles) > 5:\n",
    "        print('\\\\end{tabular}' + '\\n' + '}' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    else:\n",
    "        print('\\\\end{tabular}' + '\\n' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    # Close the file\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mo_1A-2_Tin-gamma_best-fit.txt', 'mo_1A-2_Tin-gamma_pl-eemod-ra.txt', 'mo_1B-2_Tin-gamma_best-fit.txt', 'mo_1B-2_Tin-gamma_pl-eemod-ra.txt', 'mo_2A-2_TIn-gamma_best-fit.txt', 'mo_2A-2_Tin-gamma_pl-eemod-ra.txt', 'mo_2A-2_fsc-Tin_best-fit.txt', 'mo_2A-2_fsc-Tin_pl-eemod-ra.txt', 'mo_2B-2_fsc-Tin_best-fit.txt', 'mo_2B-2_fsc-Tin_pl-eemod-ra.txt', 'mo_2C-2_fsc-Tin_pl-eemod-ra.txt', 'mo_2C-2_fsc-Tin_best-fit.txt', 'mo_2C-2_gamma-Tin_best-fit.txt', 'mo_2C-2_gamma-Tin_pl-eemod-ra.txt', 'mo_1C-2_Tin-gamma_best-fit.txt', 'mo_1C-2_Tin-gamma_pl-eemod-ra.txt', 'output.txt', 'latex_table_output.txt']\n"
     ]
    }
   ],
   "source": [
    "#get txt_file list\n",
    "path = './'\n",
    "dirs = os.listdir(path)\n",
    "txt_files = []\n",
    "for name in dirs:\n",
    "    if name.split('.')[-1] == 'txt':\n",
    "        txt_files.append(name)\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#type your txt files list:\n",
    "# infiles = ['relionCp-nk_best-fit.txt','relionCp-nk_q2-3_best-fit.txt','relionCp-nk+xillcp_logxi-0_best-fit.txt',\n",
    "#            'simp_disk+relionCp-nk_q2-free_best-fit.txt','mo_2B-1.txt','simp_disk+relionCp-nk_+xillcp_q2-free_best-fit.txt']\n",
    "# model_name = ['1A','1B','1C','2A','2B','2C']\n",
    "infiles = ['mo_1A-2_Tin-gamma_best-fit.txt',\n",
    "           'mo_1B-2_Tin-gamma_best-fit.txt',\n",
    "           'mo_1C-2_Tin-gamma_best-fit.txt',\n",
    "           'mo_2A-2_fsc-Tin_best-fit.txt',\n",
    "           'mo_2B-2_fsc-Tin_best-fit.txt',\n",
    "           'mo_2C-2_fsc-Tin_best-fit.txt']\n",
    "model_name = ['1A','1B','1C','2A','2B','2C']\n",
    "\n",
    "print_final_latex_code(infiles,model_name,debug=False,output_filename='latex_table_output.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0892ec632cc5bc01ba49379c22c0b312adff907935143a2b003e64b1c0e2b2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
