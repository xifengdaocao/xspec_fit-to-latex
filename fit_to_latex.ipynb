{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this notebook, you need to create a txt file which contains \n",
    "# the output results of xspec commands:{show free,show fit,error} (must be in this order!), \n",
    "# and you should paste the 'error' results of *all* parameters.\n",
    "\n",
    "# based on XSPEC version: 12.12.1, Not compatible with older versions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orangelee97\\AppData\\Local\\Temp\\ipykernel_11492\\3446206872.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import imp\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "#relxill_v.2.0\n",
    "relxill_family = ['relconv','relconv_lp'\n",
    "                  'relxill','relxillCp',\n",
    "                  'relxilllp','relxilllpCp',\n",
    "                  'relline','relline_lp',\n",
    "                  'relxillNS',\n",
    "                  'xillver','xillverCp',\n",
    "                  'xillverD',\n",
    "                  'xillverNS']\n",
    "#relxill_nk_v.1.6.3\n",
    "relxill_nk_family = ['relxill_nk','relxillCp_nk',\n",
    "                     'relxill_nk2',\n",
    "                     'relxillD_nk',\n",
    "                     'relline_nk',\n",
    "                     'rellinedisk_nk',\n",
    "                     'rellinelp_nk',\n",
    "                     'rellinering_nk',\n",
    "                     'relxilllp_nk','relxilllpCp_nk',\n",
    "                     'relxilllpD_nk'\n",
    "                     'relxilldgrad_nk',\n",
    "                     'relxilldisk_nk',\n",
    "                     'relxillion_nk','relxillionCp_nk',\n",
    "                     'relxilllpion_nk','relxilllpionCp_nk',\n",
    "                     'relxillring_nk']\n",
    "#combine\n",
    "rel_family = ['relconv','relconv_lp',\n",
    "              'relxill','relxillCp','relxill_nk','relxillCp_nk','relxill_nk2',\n",
    "              'relxilllp','relxilllpCp','relxilllp_nk','relxilllpCp_nk',\n",
    "              'relxilllpD_nk',\n",
    "              'relline','relline_nk','rellinedisk_nk',\n",
    "              'relline_lp','rellinelp_nk',\n",
    "              'rellinering_nk',\n",
    "              'relxilldgrad_nk',\n",
    "              'relxilldisk_nk',\n",
    "              'relxillNS',\n",
    "              'relxillD_nk',\n",
    "              'relxillion_nk','relxillionCp_nk',\n",
    "              'relxilllpion_nk','relxilllpionCp_nk',\n",
    "              'relxillring_nk'\n",
    "              'xillver','xillverCp',\n",
    "              'xillverD',\n",
    "              'xillverNS']\n",
    "\n",
    "def add_something(strs:list,add:str):\n",
    "    new_strs = []\n",
    "    for str in strs:\n",
    "        new_strs.append(add+'_'+str)\n",
    "    return new_strs\n",
    "#norm    \n",
    "norm_rel = add_something(rel_family,'norm')\n",
    "norm_2_rel = add_something(rel_family,'norm_2')\n",
    "norm_3_rel = add_something(rel_family,'norm_3')\n",
    "norm_4_rel = add_something(rel_family,'norm_4')\n",
    "norm_rel_total = norm_rel + norm_2_rel + norm_3_rel + norm_4_rel\n",
    "#logxi\n",
    "logxi_xill = add_something(rel_family,'logxi')\n",
    "logxi_2_xill = add_something(rel_family,'logxi_2')\n",
    "logxi_3_xill = add_something(rel_family,'logxi_3')\n",
    "logxi_4_xill = add_something(rel_family,'logxi_4')\n",
    "logxi_xill_total = logxi_xill + logxi_2_xill + logxi_3_xill + logxi_4_xill\n",
    "# print(logxi_xill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = ['factor_1','factor_2','factor_3','factor_4']\n",
    "dGamma = ['dGamma_1','dGamma_2','dGamma_3','dGamma_4']\n",
    "crabcorNorm = ['crabcorNorm','crabcorNorm_1','crabcorNorm_2','crabcorNorm_3','crabcorNorm_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function may need to check or modify:\n",
    "#you need check if all the parameters strings are in the *parameters lib* in the function \"sort_parameters\"\n",
    "#if not, you should add them to \"sort_parameters\" and their respective latex strings in the function \"get_latex_of_parameters\"\n",
    "def sort_parameters(key_origin,debug=False):\n",
    "    #在此函数中设定表格中参数的顺序，根据需求修改\n",
    "    #创建一个字典，键是序列keys里的元素，值是对应的latex字符串\n",
    "    #需根据实际情况进行扩充或修改。\n",
    "    if debug == True:\n",
    "        print('key_origin:')\n",
    "        print(key_origin)\n",
    "    parameter_lib = ['MaxTau',#edge\n",
    "                     'nH',#tbabs\n",
    "                     'nH_2',#tbabs_2\n",
    "                     'Tin','Tin_1','Tin_2','Tin_3','Tin_4',\n",
    "                     'norm_diskbb','norm_1_diskbb','norm_2_diskbb','norm_3_diskbb',#diskbb\n",
    "                     'Mbh','Mdd','Dbh',#kerrbb\n",
    "                     'FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4',#simplcutx\n",
    "                     'norm_cutoffpl','kT_bb',#nthcomp or cutoffpl\n",
    "                     'norm_nthComp','norm_1_nthComp','norm_2_nthComp','norm_3_nthComp','norm_4_nthComp',\n",
    "                     'T0','kT','norm_compTT',#compTT\n",
    "                     'cov_frac',#thcomp\n",
    "                     'PhoIndex','PhoIndex_1','PhoIndex_2','PhoIndex_3','PhoIndex_4','Gamma_tau','Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma','gamma_2',#power-law component\n",
    "                     'kT_e','kTe','Ecut','E_cut','HighECut','HighECut_2','HighECut_3','HighECut_4', #E_cut\n",
    "                     'h',#lamppost corona\n",
    "                     'Index1','Index2','Index3','Rbr','Rbr1','Rbr2',#emission profile\n",
    "                     'Rin',\n",
    "                     'a',#black hole\n",
    "                     'Incl','i',#accretion disk\n",
    "                     'Afe',#abundance\n",
    "                     'xi_index',#reflection\n",
    "                     'refl_frac',\n",
    "                     'logN',\n",
    "                     'LineE','LineE_2','LineE_3','LineE_4','norm_gaussian','norm_2_gaussian','norm_3_gaussian','norm_4_gaussian','Sigma','Sigma_2','Sigma_3','Sigma_4',#guassian\n",
    "                     'Xpos',#xscat\n",
    "                     'column','rlogxi','z' #xstar\n",
    "                     ] + logxi_xill_total + norm_rel_total + factor + dGamma + crabcorNorm\n",
    "    a = range(len(parameter_lib))\n",
    "    dict1 = dict(zip(a,parameter_lib))\n",
    "    if debug == True:\n",
    "        print('dict1:')\n",
    "        print(dict1)\n",
    "    dict2 = dict(zip(parameter_lib,a))\n",
    "    if debug == True:\n",
    "        print('dict2:')\n",
    "        print(dict2)\n",
    "    key_temp_1 = []\n",
    "    keys = []\n",
    "    for i in key_origin:\n",
    "        key_temp_1.append(dict2.get(i))\n",
    "    if debug == True:\n",
    "        print('key_temp_1:')\n",
    "        print(key_temp_1)\n",
    "    if debug == True:\n",
    "        for index in range(len(key_temp_1)):\n",
    "            if key_temp_1[index] == None:\n",
    "                print(\"you are missing some parameters in 'parameters_lib', please check it in function 'sort_parameters', noted that you should add a parameter in 'parameter_lib' and a latex code accordingly:\")\n",
    "                print(key_origin[index])   \n",
    "    key_temp_2 = sorted(key_temp_1)  \n",
    "    for j in key_temp_2:\n",
    "        keys.append(dict1.get(j))\n",
    "    if debug == True:\n",
    "        print('keys:')\n",
    "        print(keys)  \n",
    "    \n",
    "    return keys\n",
    "\n",
    "def get_latex_of_parameters(keys):\n",
    "    #we need to call another function to determine the output latex for some parameters\n",
    "    #such as: Index1,2, Rbr(nk or not nk)\n",
    "    #factor:output without the instrument names, you should fill it by yourself.\n",
    "    number = len(keys)\n",
    "    keys_latex = [None]*number\n",
    "    for i in range(number):\n",
    "        #edge\n",
    "        if keys[i] == 'MaxTau':\n",
    "            keys_latex[i] = '$\\\\tau_{\\\\tt max}$'\n",
    "        #tbabs\n",
    "        if keys[i] in ['nH','nH_2']:\n",
    "            keys_latex[i] = '$N_{\\\\rm H}$ [\\\\(10^{22}\\\\) cm\\\\(^{-2}\\\\)]'\n",
    "        #diskbb\n",
    "        if keys[i] in ['Tin','Tin_1','Tin_2','Tin_3','Tin_4']:\n",
    "            keys_latex[i] = '$T_{\\\\rm in}$'\n",
    "        #kerrbb\n",
    "        if keys[i] == 'Mbh':\n",
    "            keys_latex[i] = '$M$'\n",
    "        if keys[i] == 'Mdd':\n",
    "            keys_latex[i] = '$\\dot M$'\n",
    "        if keys[i] == 'Dbh':\n",
    "            keys_latex[i] = '$D$'\n",
    "        #simplcutx\n",
    "        if keys[i] in ['FracSctr','FracSctr_1','FracSctr_2','FracSctr_3','FracSctr_4','FracSctr_5']:\n",
    "            keys_latex[i] = '$f_{\\\\tt SC}$'\n",
    "        #nthcomp\n",
    "        if keys[i] == 'kT_bb':\n",
    "            keys_latex[i] = '$kT_{bb}$'\n",
    "        #compTT\n",
    "        if keys[i] == 'T0':\n",
    "            keys_latex[i] = '$T_{0}$'\n",
    "        if keys[i] == 'kT':\n",
    "            keys_latex[i] = '$T_{plasma}$'\n",
    "        #thcomp\n",
    "        if keys[i] == 'cov_frac':\n",
    "            keys_latex[i] = '$cov_{\\\\rm frac}$'\n",
    "        if keys[i] == 'Gamma_tau':\n",
    "            keys_latex[i] = '$\\\\Gamma_{\\\\tau}$'\n",
    "        #power-law component\n",
    "        if keys[i] in ['Gamma','Gamma_1','Gamma_2','Gamma_3','Gamma_4','gamma','gamma_2','PhoIndex','PhoIndex_2','PhoIndex_3','PhoIndex_4']:\n",
    "            keys_latex[i] = '$\\\\Gamma$'\n",
    "        if keys[i] in ['kT_e','kTe']:\n",
    "            keys_latex[i] = '$kT_{\\\\rm e}$ [keV]'\n",
    "        if keys[i] in ['E_cut','Ecut','HighECut','HighECut','HighECut_2','HighECut_3','HighECut_4']:\n",
    "            keys_latex[i] = '$E_{\\\\rm cut}$'\n",
    "        #lamppost corona\n",
    "        if keys[i] == 'h':\n",
    "            keys_latex[i] = '$h$'\n",
    "        #emission profiles\n",
    "        if keys[i] == 'Index1':\n",
    "            keys_latex[i] = '$q_{\\\\rm in}$'\n",
    "        if keys[i] == 'Index2':\n",
    "            keys_latex[i] = '$q_{\\\\rm out}$ '\n",
    "        if keys[i] == 'Index3':\n",
    "            keys_latex[i] = '$q_{3}$'\n",
    "        if keys[i] == 'Rbr':\n",
    "            keys_latex[i] = '$R_{\\\\rm br}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr1':\n",
    "            keys_latex[i] = '$R_{\\\\rm br1}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rbr2':\n",
    "            keys_latex[i] = '$R_{\\\\rm br2}$ [$R_{\\\\rm g}$]'\n",
    "        if keys[i] == 'Rin':\n",
    "            keys_latex[i] = '$R_{\\\\rm in}$'\n",
    "        #black hole\n",
    "        if keys[i] == 'a':\n",
    "            keys_latex[i] = '$a_{*}$'\n",
    "        #accretion disk\n",
    "        if keys[i] in ['Incl','i']:\n",
    "            keys_latex[i] = '$i$ [deg]'\n",
    "        #abundance\n",
    "        if keys[i] == 'Afe':\n",
    "            keys_latex[i] = 'A$_{\\\\rm Fe}$'\n",
    "        #reflection\n",
    "        if keys[i] == 'xi_index':\n",
    "            keys_latex[i] = '$\\\\alpha_{\\\\xi}$' \n",
    "        if keys[i] == 'refl_frac':\n",
    "            keys_latex[i] = '$R_{\\\\rm f}$'\n",
    "        if keys[i] == 'logN':\n",
    "            keys_latex[i] = 'log${\\\\rm N}$'\n",
    "        #guassian\n",
    "        if keys[i] in ['LineE','LineE_2','LineE_3','LineE_4']:\n",
    "            keys_latex[i] = '$E_{\\\\rm line}$'\n",
    "        if keys[i] in ['Sigma','Sigma_2','Sigma_3','Sigma_4']:\n",
    "            keys_latex[i] = '$\\\\sigma$'\n",
    "        #xscat\n",
    "        if keys[i] == 'Xpos':\n",
    "            keys_latex[i] = '$x$'\n",
    "        #norm\n",
    "        if keys[i].split('_')[0] == 'norm':\n",
    "            if len(keys[i].split('_')) == 2:\n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[1] + '})'\n",
    "            else: \n",
    "                keys_latex[i] = 'Norm({\\\\tt ' + keys[i].split('_')[2] + keys[i].split('_')[1] + '})'\n",
    "        #logxi\n",
    "        if keys[i].split('_')[0] == 'logxi':\n",
    "            if keys[i].split('_')[1] in ['2','3','4']:\n",
    "                keys_latex[i] = 'log${\\\\xi}$(' + keys[i].split('_')[2] + keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "            else:\n",
    "                keys_latex[i] = 'log${\\\\xi}$('+ keys[i].split('_')[1] +')[erg~cm~s$^{-1}$]'\n",
    "        #xstar\n",
    "        if keys[i] == 'column':\n",
    "            keys_latex[i] = '$N_{\\\\rm H}$ (XSTAR)'\n",
    "        if keys[i] == 'rlogxi':\n",
    "            keys_latex[i] = 'log${\\\\xi}$ ([erg~cm~s$^{-1}$]) (XSTAR)'\n",
    "        if keys[i] ==  'z':\n",
    "            keys_latex[i] = '$z$'\n",
    "        #factor:output without the instrument names, you should fill it by yourself in latex.\n",
    "        if keys[i].split('_')[0] == 'factor':\n",
    "            keys_latex[i] = '$C_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'dGamma':\n",
    "            keys_latex[i] = '$\\\\rm dGamma_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "        if keys[i].split('_')[0] == 'crabcorNorm':\n",
    "            keys_latex[i] = '$\\\\rm crabcorNorm_{\\\\rm instrument' + keys[i].split('_')[1] + '}$'\n",
    "    par_latex = dict(zip(keys,keys_latex))\n",
    "    return par_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt file pre-treatment\n",
    "def do_something2multifiles(infiles:list):\n",
    "    for infile in infiles:\n",
    "        delete_hashtag_and_blank_line(infile)\n",
    "        add_index2par_single_file(infile)\n",
    "        delete_useless_str(infile)\n",
    "        mod_nk(infile)\n",
    "        i2incl(infile)\n",
    "        show_par2show_free(infile)\n",
    "    check_Rbr(infiles)\n",
    "        \n",
    "def delete_hashtag_and_blank_line(file): \n",
    "    # \"#\"and blank line should be removed first.\n",
    "    file_data = \"\"\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if '#' in line:\n",
    "                    line = line.replace('#','')\n",
    "                if line == '\\n':\n",
    "                    line = line.strip(\"\\n\")           \n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "\n",
    "def delete_useless_str(file):\n",
    "    # 请先保证文档没有空行。\n",
    "    file_data = \"\"   \n",
    "    str_delete = ['Apparent','Current','and','but','Suggest',\n",
    "                  'Error','***','caused','Parameter','***Warning:','Due','Suggest','pparent','Please','will automatically exit','Last','will','parameter','Upper']    \n",
    "    with open(file, \"r\") as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line.split() == []:\n",
    "                continue\n",
    "            if line.split()[0] not in str_delete:\n",
    "                file_data += line   \n",
    "    with open(file,\"w\",encoding=\"utf-8\") as output:\n",
    "        output.write(file_data) \n",
    "    \n",
    "def add_index2par_single_file(infile):\n",
    "    #example: factor -> factor_2; factor -> factor_3\n",
    "    #example: nH -> nH_2\n",
    "    file_data = \"\"\n",
    "    index = ''\n",
    "    with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if len(lines[i].split()) < 3:\n",
    "                continue\n",
    "            elif lines[i].split()[0] == 'Data' and lines[i].split()[2] != '1':\n",
    "                #第零行:数据组标题\n",
    "                index = lines[i].split()[2]\n",
    "                #第一行\n",
    "                factor = lines[i+1].split()[3]\n",
    "                if factor == 'factor':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('factor','factor'+'_'+index)\n",
    "                if factor == 'dGamma':\n",
    "                    #if not, it means that it have already been changed\n",
    "                    lines[i+1] = lines[i+1].replace('dGamma','dGamma'+'_'+index)\n",
    "                if factor == 'Tin':\n",
    "                    lines[i+1] = lines[i+1].replace('Tin','Tin'+'_'+index)\n",
    "                if factor == 'FracSctr':\n",
    "                    lines[i+1] = lines[i+1].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                if factor == 'PhoIndex':\n",
    "                    lines[i+1] = lines[i+1].replace('PhoIndex','PhoIndex'+'_'+index)\n",
    "                if factor == 'crabcorNorm':\n",
    "                    lines[i+1] = lines[i+1].replace('crabcorNorm','crabcorNorm'+'_'+index)\n",
    "                #第二行\n",
    "                if len(lines[i+2].split()) > 3:\n",
    "                    factor2 = lines[i+2].split()[3]\n",
    "                    if factor2 == 'nH':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('nH','nH'+'_'+index)\n",
    "                    if factor2 == 'crabcorNorm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('crabcorNorm','crabcorNorm'+'_'+index)\n",
    "                    if factor2 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+2] = lines[i+2].replace('norm','norm'+'_'+index)\n",
    "                    if factor2 == 'Tin':\n",
    "                        lines[i+2] = lines[i+2].replace('Tin','Tin'+'_'+index)\n",
    "                    if factor2 == 'HighECut':\n",
    "                        lines[i+2] = lines[i+2].replace('HighECut','HighECut'+'_'+index)\n",
    "                    if factor2 == 'gamma':\n",
    "                        lines[i+2] = lines[i+2].replace('gamma','gamma'+'_'+index)\n",
    "                #第三行\n",
    "                if len(lines[i+3].split()) > 3:\n",
    "                    factor3 = lines[i+3].split()[3]\n",
    "                    if factor3 == 'Tin':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+3] = lines[i+3].replace('Tin','Tin'+'_'+index)\n",
    "                    if factor3 == 'FracSctr':\n",
    "                        lines[i+3] = lines[i+3].replace('FracSctr','FracSctr'+'_'+index)\n",
    "                #第四行\n",
    "                if len(lines[i+4].split()) > 3:\n",
    "                    factor4 = lines[i+4].split()[3]\n",
    "                    if factor4 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+4] = lines[i+4].replace('norm','norm'+'_'+index)\n",
    "                    if factor4 == 'Tin':\n",
    "                        lines[i+4] = lines[i+4].replace('Tin','Tin'+'_'+index)  \n",
    "                    if factor4 == 'Gamma':\n",
    "                        lines[i+4] = lines[i+4].replace('Gamma','Gamma'+'_'+index)   \n",
    "                #第五行      \n",
    "                if len(lines[i+5].split()) > 3:\n",
    "                    factor5 = lines[i+5].split()[3]\n",
    "                    if factor5 == 'logxi':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+5] = lines[i+5].replace('logxi','logxi'+'_'+index)    \n",
    "                #第六行      \n",
    "                if len(lines[i+6].split()) > 3:\n",
    "                    factor6 = lines[i+6].split()[3]\n",
    "                    if factor6 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+6] = lines[i+6].replace('norm','norm'+'_'+index) \n",
    "                #第七行\n",
    "                if len(lines[i+7].split()) > 3:\n",
    "                    factor7 = lines[i+7].split()[3]\n",
    "                    if factor7 == 'LineE':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+7] = lines[i+7].replace('LineE','LineE'+'_'+index) \n",
    "                #第八行\n",
    "                if len(lines[i+8].split()) > 3:\n",
    "                    factor8 = lines[i+8].split()[3]\n",
    "                    if factor8 == 'Sigma':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+8] = lines[i+8].replace('Sigma','Sigma'+'_'+index) \n",
    "                #第九行\n",
    "                if len(lines[i+9].split()) > 3:\n",
    "                    factor9 = lines[i+9].split()[3]\n",
    "                    if factor9 == 'norm':\n",
    "                    #if not, it means that it have already been changed\n",
    "                        lines[i+9] = lines[i+9].replace('norm','norm'+'_'+index) \n",
    "        for line in lines:\n",
    "            file_data += line\n",
    "    with open(infile, \"w\", encoding=\"utf-8\") as f: \n",
    "        f.write(file_data)      \n",
    "\n",
    "def mod_nk(file):\n",
    "    #因为nk后缀会破坏按行切分\n",
    "    # 替换文件中的字符串,把rexill_nk的后缀nk去掉。这个函数对需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace('_nk','_nk ')\n",
    "            line = line.replace('relxilllpCp','relxilllpCp ')\n",
    "            file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data) \n",
    "           \n",
    "def check_Rbr(files:list):\n",
    "    #first, make a judgement and decide whether to replace 'Rbr' with 'Rbr_1'\n",
    "    a = 0\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\" utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if 'Rbr_2' in line.split():\n",
    "                    a += 1\n",
    "    if a > 0:        \n",
    "        for file in files:\n",
    "        # 替换文件中的字符串,把Rbr替换为Rbr_1。这是因为我们需要把relxill和relxill_nk放在同一行比较时才有用。\n",
    "            file_data = \"\"\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if ('Rbr' in line) and ('Rbr1' not in line) and ('Rbr2' not in line):\n",
    "                        line = line.replace('Rbr','Rbr1')\n",
    "                    file_data += line\n",
    "            with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(file_data)\n",
    "                f.close()  \n",
    "                \n",
    "def i2incl(file):\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) < 4:\n",
    "                file_data += line\n",
    "            else:\n",
    "                if line.split()[3] == 'i':\n",
    "                    line = line.replace('i','Incl')\n",
    "                file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)     \n",
    "          \n",
    "def show_par2show_free(file):\n",
    "    #get error list\n",
    "    error_list = []\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) == 4:\n",
    "                if len(line.split()[-1].split(',')) == 2:\n",
    "                    error_list.append(line.split()[0])\n",
    "    #read show par and copy some fo them\n",
    "    file_data = \"\"\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'par' and line.split()[1] == 'comp':\n",
    "                    start_index = int(x[0]) + 2\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:               \n",
    "        for x in enumerate(f):\n",
    "            line = x[1]\n",
    "            if len(line.split()) > 1:\n",
    "                if line.split()[0] == 'Fit':\n",
    "                    end_index = int(x[0]) - 1\n",
    "    with open(file,\"r\", encoding=\"utf-8\") as f:\n",
    "        for x in enumerate(f):\n",
    "            copy = True\n",
    "            index = x[0]\n",
    "            line = x[1]\n",
    "            if index >= start_index and index <= end_index:\n",
    "                if len(line.split()) > 1:\n",
    "                    if line.split()[0] == 'Data':\n",
    "                        copy = True\n",
    "                    elif line.split()[0] in error_list:\n",
    "                        copy = True\n",
    "                    else:\n",
    "                        copy = False        \n",
    "                else:\n",
    "                    copy = True\n",
    "            else:\n",
    "                copy = True     \n",
    "            if copy == True:\n",
    "                file_data += line\n",
    "    #write down the new file\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters values from the data\n",
    "def get_par_best_error(infile):\n",
    "    \n",
    "    index = []\n",
    "    parameter = []\n",
    "    best_fit = []\n",
    "    bound = []\n",
    "    data_group_index = ''\n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                if (line.split()[3] in ['norm','norm_1','norm_2','norm_3','norm_4'] or line.split()[3] in ['logxi','logxi_2','logxi_3','logxi_4']):\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3] + \"_\" + line.split()[2])\n",
    "                    #example: 'norm' + '_' + 'nthcomp'\n",
    "                else:\n",
    "                    index.append(line.split()[0])\n",
    "                    parameter.append(line.split()[3])\n",
    "    parameters = dict(zip(index,parameter))\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4: \n",
    "            if line.split()[-2] == '+/-':\n",
    "                index.append(line.split()[0])\n",
    "                best_fit.append(line.split()[-3])\n",
    "    best = dict(zip(index,best_fit)) \n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>3:\n",
    "            if line.split()[-1][-1]==\")\":\n",
    "                if len(line.split()[-1].split(','))>1.1:\n",
    "                    index.append(line.split()[0])\n",
    "                    bound.append([line.split()[1], line.split()[2]])\n",
    "                    \n",
    "    bounds = dict(zip(index,bound))\n",
    "    \n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return parameters, best, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latex elements\n",
    "def get_latex_elements_single_file(infile,debug=False):\n",
    "    import imp\n",
    "    import error2latex as el\n",
    "    imp.reload(el)\n",
    "    \n",
    "    parameter, best_fit, bounds = get_par_best_error(infile)\n",
    "    \n",
    "    #index = []\n",
    "    par = []\n",
    "    latex_c = []\n",
    "    \n",
    "    if len(best_fit)!=len(bounds):\n",
    "        print(\"Error: best-fit parameters do not match the number of uncertainties\")\n",
    "        print(f\"Number of free parameters: {len(best_fit)}, number of boundaries: {len(bounds)}\")\n",
    "    \n",
    "    for key in best_fit.keys():\n",
    "        name = parameter[key]\n",
    "        best = best_fit[key]\n",
    "        lower = bounds[key][0]\n",
    "        upper = bounds[key][1]\n",
    "        string, value_base, err_low_base, err_high_base = el.get_xspec_error(best, lower, upper) \n",
    "        \n",
    "        #index.append(key)\n",
    "        par.append(name)\n",
    "        latex_c.append(string)    \n",
    "        \n",
    "       # print(string)\n",
    "    #result = dict(zip(index,latex_c))\n",
    "    # print(par)\n",
    "    result = dict(zip(par,latex_c))\n",
    "    if debug == True:\n",
    "        print('Hey! latex elements have been got from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_latex_elements_multiple_file(infiles,debug=False):\n",
    "    number = len(infiles)\n",
    "    elements = [None]*number\n",
    "    for i in range(number):\n",
    "        if debug == False:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i])\n",
    "        else:\n",
    "            elements[i] = get_latex_elements_single_file(infiles[i],debug=True)\n",
    "    pars = []\n",
    "    \n",
    "    for i in range(number):\n",
    "        pars = pars + list(elements[i].keys())\n",
    "    keys_origin = list(set(pars))\n",
    "    \n",
    "    if debug == True:\n",
    "        keys = sort_parameters(keys_origin,debug=True)\n",
    "    else:\n",
    "        keys = sort_parameters(keys_origin)\n",
    "        \n",
    "    return elements, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics values and its latex code\n",
    "def get_chi_sq_and_AICc_single_file(infile):\n",
    "# based on XSPEC version: 12.12.1, not Not compatible with older versions! \n",
    "# because the xspec outputs of \"show fit\" are different in version: 12.12.1 \n",
    "    \n",
    "    f = open(infile, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    index = ['chisq','dof','reduced_chisq','N-bin','N-par','AICc']\n",
    "    value = [None]*6\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.split()[0] == 'Test' and line.split()[-1] == 'bins.':\n",
    "            value[3] = int(line.split()[-2])\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split())>4:\n",
    "            if line.split()[-1] == 'd.o.f.':\n",
    "                value[0] = float(line.split()[3])\n",
    "                value[1] = int(line.split()[-2])\n",
    "                value[2] = float(\"{:.5f}\".format(value[0] / value[1]))\n",
    "\n",
    "    value[4] = value[3] - value[1]\n",
    "    \n",
    "    value[5] = float(\"{:.2f}\".format(value[0] + 2*value[4] + 2*value[4]*(value[4]+1)/(value[3]-value[4]-1)))\n",
    "    \n",
    "    result = dict(zip(index,value))\n",
    "    \n",
    "#     print('got statistic from ' + infile)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_chi_sq_and_AICc_multiple_files(infiles, outfile):\n",
    "    \n",
    "    number = len(infiles)\n",
    "    chisq, dof, reduced_chisq, AICc = [None]*number, [None]*number, [None]*number, [None]*number\n",
    "    for i in range(number):\n",
    "        chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('chisq')\n",
    "        dof[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('dof')\n",
    "        reduced_chisq[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('reduced_chisq')\n",
    "        AICc[i] = get_chi_sq_and_AICc_single_file(infiles[i]).get('AICc')\n",
    "\n",
    "    string = '$\\chi^2$ /dof'\n",
    "    \n",
    "    string_AICc = 'AICc'\n",
    "    \n",
    "    for n in range(number):\n",
    "        string = string + ' & ' +'\\\\tabincell{c}{' + str(chisq[n]) + '/' + str(dof[n]) + '=\\\\\\\\' + str(reduced_chisq[n]) + '}'\n",
    "        string_AICc = string_AICc + ' & ' + str(AICc[n])\n",
    "        \n",
    "    print('\\\\hline' + '\\n\\n' + string + '\\\\\\\\' + '\\n\\n' + string_AICc +  '\\\\\\\\' + '\\n\\n' + '\\\\hline' + '\\n', file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally,print the full latex code\n",
    "def print_final_latex_code(infiles:list,model_name:list,debug=False,output_filename='latex_table_output.txt'):\n",
    "    # Open the file for writing\n",
    "    output_file = open(output_filename, \"w\")\n",
    "        \n",
    "    do_something2multifiles(infiles)\n",
    "    if debug == True:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles,debug=True)\n",
    "    else:\n",
    "        elements, keys = get_latex_elements_multiple_file(infiles)\n",
    "    #去掉多余的减号\n",
    "    for i in range(len(infiles)):\n",
    "        for key in elements[i].keys():\n",
    "            elements[i][key] = elements[i][key].replace('{--','{-')\n",
    "    if debug == True:\n",
    "        print('elements: ')\n",
    "        print(elements)\n",
    "    \n",
    "    par_latex = get_latex_of_parameters(keys)\n",
    "    # print(par_latex)\n",
    "    \n",
    "    # newcommand reminder:\n",
    "    \n",
    "    print(\"please copy this to the front of your .tex file in order to use commands:'tabincell':\\n\", file=output_file)\n",
    "    print(\"\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}\\n\", file=output_file)\n",
    "    \n",
    "    print(\"###########################################################################################################################\", file=output_file)\n",
    "    \n",
    "    #resizebox or not\n",
    "    if len(infiles) > 5:\n",
    "        print('\\n'+'%please copy this line to the front of your .tex document in order to use \\\\tabincell: '+ '\\n'\n",
    "              +'\\\\newcommand{\\\\tabincell}[2]{\\\\begin{tabular}{@{}#1@{}}#2\\\\end{tabular}}' + '\\n', file=output_file)\n",
    "        \n",
    "        print(\"###########################################################################################################################\", file=output_file)\n",
    "        \n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n' + '\\\\resizebox{\\\\textwidth}{70mm}{' , file=output_file)\n",
    "    else:\n",
    "        print('\\\\begin{table*}' + '\\n' + '\\\\centering' + '\\n' + '\\\\renewcommand\\\\arraystretch{1.5}' + '\\n' \n",
    "              + '\\\\caption{}' + '\\n' + '\\\\label{}' + '\\n', file=output_file)\n",
    "    #table\n",
    "    chart = '' \n",
    "    for i in range(len(infiles)):\n",
    "        chart += 'c'\n",
    "\n",
    "    print('\\\\begin{tabular}{l' + chart + '}'+ '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    model = 'Model'\n",
    "    for i in range(len(infiles)):\n",
    "        model += (' & ' + 'Model ' + model_name[i])\n",
    "    \n",
    "    print(model + '\\\\\\\\' + '\\n', file=output_file)\n",
    "    \n",
    "    print('\\\\hline' + '\\n', file=output_file)\n",
    "    \n",
    "    for par in keys:\n",
    "        string = par_latex.get(par)\n",
    "        for n in range(len(infiles)):\n",
    "            if par in set(list(elements[n].keys())):\n",
    "    #                 print(string)\n",
    "                string = string + ' & '+ elements[n][par]\n",
    "            else:\n",
    "                string = string + ' & ' + ' - '\n",
    "        print(string + '\\\\\\\\' + '\\n', file=output_file)\n",
    "\n",
    "    print_chi_sq_and_AICc_multiple_files(infiles, output_file)\n",
    "    \n",
    "    #print AICc\n",
    "    \n",
    "    if len(infiles) > 5:\n",
    "        print('\\\\end{tabular}' + '\\n' + '}' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    else:\n",
    "        print('\\\\end{tabular}' + '\\n' + '\\n' + '\\\\end{table*}', file=output_file)\n",
    "    # Close the file\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latex_table_output.txt', 'mo_1A-2_coupled_best-fit.txt', 'mo_2A-2_coupled_best-fit.txt', 'swiftJ1658_RTOFF.txt', 'swiftJ1658_RTON.txt']\n"
     ]
    }
   ],
   "source": [
    "#get txt_file list\n",
    "path = './'\n",
    "dirs = os.listdir(path)\n",
    "txt_files = []\n",
    "for name in dirs:\n",
    "    if name.split('.')[-1] == 'txt':\n",
    "        txt_files.append(name)\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! latex elements have been got from swiftJ1658_RTOFF.txt\n",
      "Hey! latex elements have been got from swiftJ1658_RTON.txt\n",
      "key_origin:\n",
      "['gamma_2', 'gamma', 'z', 'norm_relxilllpCp', 'column', 'factor_2', 'h', 'nH', 'kTe', 'rlogxi', 'Afe', 'logN', 'Incl', 'logxi_relxilllpCp', 'refl_frac', 'a', 'Sigma', 'norm_gaussian', 'LineE', 'factor_3']\n",
      "dict1:\n",
      "{0: 'MaxTau', 1: 'nH', 2: 'nH_2', 3: 'Tin', 4: 'Tin_1', 5: 'Tin_2', 6: 'Tin_3', 7: 'Tin_4', 8: 'norm_diskbb', 9: 'norm_1_diskbb', 10: 'norm_2_diskbb', 11: 'norm_3_diskbb', 12: 'Mbh', 13: 'Mdd', 14: 'Dbh', 15: 'FracSctr', 16: 'FracSctr_1', 17: 'FracSctr_2', 18: 'FracSctr_3', 19: 'FracSctr_4', 20: 'norm_cutoffpl', 21: 'kT_bb', 22: 'norm_nthComp', 23: 'norm_1_nthComp', 24: 'norm_2_nthComp', 25: 'norm_3_nthComp', 26: 'norm_4_nthComp', 27: 'T0', 28: 'kT', 29: 'norm_compTT', 30: 'cov_frac', 31: 'PhoIndex', 32: 'PhoIndex_1', 33: 'PhoIndex_2', 34: 'PhoIndex_3', 35: 'PhoIndex_4', 36: 'Gamma_tau', 37: 'Gamma', 38: 'Gamma_1', 39: 'Gamma_2', 40: 'Gamma_3', 41: 'Gamma_4', 42: 'gamma', 43: 'gamma_2', 44: 'kT_e', 45: 'kTe', 46: 'Ecut', 47: 'E_cut', 48: 'HighECut', 49: 'HighECut_2', 50: 'HighECut_3', 51: 'HighECut_4', 52: 'h', 53: 'Index1', 54: 'Index2', 55: 'Index3', 56: 'Rbr', 57: 'Rbr1', 58: 'Rbr2', 59: 'Rin', 60: 'a', 61: 'Incl', 62: 'i', 63: 'Afe', 64: 'xi_index', 65: 'refl_frac', 66: 'logN', 67: 'LineE', 68: 'LineE_2', 69: 'LineE_3', 70: 'LineE_4', 71: 'norm_gaussian', 72: 'norm_2_gaussian', 73: 'norm_3_gaussian', 74: 'norm_4_gaussian', 75: 'Sigma', 76: 'Sigma_2', 77: 'Sigma_3', 78: 'Sigma_4', 79: 'Xpos', 80: 'column', 81: 'rlogxi', 82: 'z', 83: 'logxi_relconv', 84: 'logxi_relconv_lp', 85: 'logxi_relxill', 86: 'logxi_relxillCp', 87: 'logxi_relxill_nk', 88: 'logxi_relxillCp_nk', 89: 'logxi_relxill_nk2', 90: 'logxi_relxilllp', 91: 'logxi_relxilllpCp', 92: 'logxi_relxilllp_nk', 93: 'logxi_relxilllpCp_nk', 94: 'logxi_relxilllpD_nk', 95: 'logxi_relline', 96: 'logxi_relline_nk', 97: 'logxi_rellinedisk_nk', 98: 'logxi_relline_lp', 99: 'logxi_rellinelp_nk', 100: 'logxi_rellinering_nk', 101: 'logxi_relxilldgrad_nk', 102: 'logxi_relxilldisk_nk', 103: 'logxi_relxillNS', 104: 'logxi_relxillD_nk', 105: 'logxi_relxillion_nk', 106: 'logxi_relxillionCp_nk', 107: 'logxi_relxilllpion_nk', 108: 'logxi_relxilllpionCp_nk', 109: 'logxi_relxillring_nkxillver', 110: 'logxi_xillverCp', 111: 'logxi_xillverD', 112: 'logxi_xillverNS', 113: 'logxi_2_relconv', 114: 'logxi_2_relconv_lp', 115: 'logxi_2_relxill', 116: 'logxi_2_relxillCp', 117: 'logxi_2_relxill_nk', 118: 'logxi_2_relxillCp_nk', 119: 'logxi_2_relxill_nk2', 120: 'logxi_2_relxilllp', 121: 'logxi_2_relxilllpCp', 122: 'logxi_2_relxilllp_nk', 123: 'logxi_2_relxilllpCp_nk', 124: 'logxi_2_relxilllpD_nk', 125: 'logxi_2_relline', 126: 'logxi_2_relline_nk', 127: 'logxi_2_rellinedisk_nk', 128: 'logxi_2_relline_lp', 129: 'logxi_2_rellinelp_nk', 130: 'logxi_2_rellinering_nk', 131: 'logxi_2_relxilldgrad_nk', 132: 'logxi_2_relxilldisk_nk', 133: 'logxi_2_relxillNS', 134: 'logxi_2_relxillD_nk', 135: 'logxi_2_relxillion_nk', 136: 'logxi_2_relxillionCp_nk', 137: 'logxi_2_relxilllpion_nk', 138: 'logxi_2_relxilllpionCp_nk', 139: 'logxi_2_relxillring_nkxillver', 140: 'logxi_2_xillverCp', 141: 'logxi_2_xillverD', 142: 'logxi_2_xillverNS', 143: 'logxi_3_relconv', 144: 'logxi_3_relconv_lp', 145: 'logxi_3_relxill', 146: 'logxi_3_relxillCp', 147: 'logxi_3_relxill_nk', 148: 'logxi_3_relxillCp_nk', 149: 'logxi_3_relxill_nk2', 150: 'logxi_3_relxilllp', 151: 'logxi_3_relxilllpCp', 152: 'logxi_3_relxilllp_nk', 153: 'logxi_3_relxilllpCp_nk', 154: 'logxi_3_relxilllpD_nk', 155: 'logxi_3_relline', 156: 'logxi_3_relline_nk', 157: 'logxi_3_rellinedisk_nk', 158: 'logxi_3_relline_lp', 159: 'logxi_3_rellinelp_nk', 160: 'logxi_3_rellinering_nk', 161: 'logxi_3_relxilldgrad_nk', 162: 'logxi_3_relxilldisk_nk', 163: 'logxi_3_relxillNS', 164: 'logxi_3_relxillD_nk', 165: 'logxi_3_relxillion_nk', 166: 'logxi_3_relxillionCp_nk', 167: 'logxi_3_relxilllpion_nk', 168: 'logxi_3_relxilllpionCp_nk', 169: 'logxi_3_relxillring_nkxillver', 170: 'logxi_3_xillverCp', 171: 'logxi_3_xillverD', 172: 'logxi_3_xillverNS', 173: 'logxi_4_relconv', 174: 'logxi_4_relconv_lp', 175: 'logxi_4_relxill', 176: 'logxi_4_relxillCp', 177: 'logxi_4_relxill_nk', 178: 'logxi_4_relxillCp_nk', 179: 'logxi_4_relxill_nk2', 180: 'logxi_4_relxilllp', 181: 'logxi_4_relxilllpCp', 182: 'logxi_4_relxilllp_nk', 183: 'logxi_4_relxilllpCp_nk', 184: 'logxi_4_relxilllpD_nk', 185: 'logxi_4_relline', 186: 'logxi_4_relline_nk', 187: 'logxi_4_rellinedisk_nk', 188: 'logxi_4_relline_lp', 189: 'logxi_4_rellinelp_nk', 190: 'logxi_4_rellinering_nk', 191: 'logxi_4_relxilldgrad_nk', 192: 'logxi_4_relxilldisk_nk', 193: 'logxi_4_relxillNS', 194: 'logxi_4_relxillD_nk', 195: 'logxi_4_relxillion_nk', 196: 'logxi_4_relxillionCp_nk', 197: 'logxi_4_relxilllpion_nk', 198: 'logxi_4_relxilllpionCp_nk', 199: 'logxi_4_relxillring_nkxillver', 200: 'logxi_4_xillverCp', 201: 'logxi_4_xillverD', 202: 'logxi_4_xillverNS', 203: 'norm_relconv', 204: 'norm_relconv_lp', 205: 'norm_relxill', 206: 'norm_relxillCp', 207: 'norm_relxill_nk', 208: 'norm_relxillCp_nk', 209: 'norm_relxill_nk2', 210: 'norm_relxilllp', 211: 'norm_relxilllpCp', 212: 'norm_relxilllp_nk', 213: 'norm_relxilllpCp_nk', 214: 'norm_relxilllpD_nk', 215: 'norm_relline', 216: 'norm_relline_nk', 217: 'norm_rellinedisk_nk', 218: 'norm_relline_lp', 219: 'norm_rellinelp_nk', 220: 'norm_rellinering_nk', 221: 'norm_relxilldgrad_nk', 222: 'norm_relxilldisk_nk', 223: 'norm_relxillNS', 224: 'norm_relxillD_nk', 225: 'norm_relxillion_nk', 226: 'norm_relxillionCp_nk', 227: 'norm_relxilllpion_nk', 228: 'norm_relxilllpionCp_nk', 229: 'norm_relxillring_nkxillver', 230: 'norm_xillverCp', 231: 'norm_xillverD', 232: 'norm_xillverNS', 233: 'norm_2_relconv', 234: 'norm_2_relconv_lp', 235: 'norm_2_relxill', 236: 'norm_2_relxillCp', 237: 'norm_2_relxill_nk', 238: 'norm_2_relxillCp_nk', 239: 'norm_2_relxill_nk2', 240: 'norm_2_relxilllp', 241: 'norm_2_relxilllpCp', 242: 'norm_2_relxilllp_nk', 243: 'norm_2_relxilllpCp_nk', 244: 'norm_2_relxilllpD_nk', 245: 'norm_2_relline', 246: 'norm_2_relline_nk', 247: 'norm_2_rellinedisk_nk', 248: 'norm_2_relline_lp', 249: 'norm_2_rellinelp_nk', 250: 'norm_2_rellinering_nk', 251: 'norm_2_relxilldgrad_nk', 252: 'norm_2_relxilldisk_nk', 253: 'norm_2_relxillNS', 254: 'norm_2_relxillD_nk', 255: 'norm_2_relxillion_nk', 256: 'norm_2_relxillionCp_nk', 257: 'norm_2_relxilllpion_nk', 258: 'norm_2_relxilllpionCp_nk', 259: 'norm_2_relxillring_nkxillver', 260: 'norm_2_xillverCp', 261: 'norm_2_xillverD', 262: 'norm_2_xillverNS', 263: 'norm_3_relconv', 264: 'norm_3_relconv_lp', 265: 'norm_3_relxill', 266: 'norm_3_relxillCp', 267: 'norm_3_relxill_nk', 268: 'norm_3_relxillCp_nk', 269: 'norm_3_relxill_nk2', 270: 'norm_3_relxilllp', 271: 'norm_3_relxilllpCp', 272: 'norm_3_relxilllp_nk', 273: 'norm_3_relxilllpCp_nk', 274: 'norm_3_relxilllpD_nk', 275: 'norm_3_relline', 276: 'norm_3_relline_nk', 277: 'norm_3_rellinedisk_nk', 278: 'norm_3_relline_lp', 279: 'norm_3_rellinelp_nk', 280: 'norm_3_rellinering_nk', 281: 'norm_3_relxilldgrad_nk', 282: 'norm_3_relxilldisk_nk', 283: 'norm_3_relxillNS', 284: 'norm_3_relxillD_nk', 285: 'norm_3_relxillion_nk', 286: 'norm_3_relxillionCp_nk', 287: 'norm_3_relxilllpion_nk', 288: 'norm_3_relxilllpionCp_nk', 289: 'norm_3_relxillring_nkxillver', 290: 'norm_3_xillverCp', 291: 'norm_3_xillverD', 292: 'norm_3_xillverNS', 293: 'norm_4_relconv', 294: 'norm_4_relconv_lp', 295: 'norm_4_relxill', 296: 'norm_4_relxillCp', 297: 'norm_4_relxill_nk', 298: 'norm_4_relxillCp_nk', 299: 'norm_4_relxill_nk2', 300: 'norm_4_relxilllp', 301: 'norm_4_relxilllpCp', 302: 'norm_4_relxilllp_nk', 303: 'norm_4_relxilllpCp_nk', 304: 'norm_4_relxilllpD_nk', 305: 'norm_4_relline', 306: 'norm_4_relline_nk', 307: 'norm_4_rellinedisk_nk', 308: 'norm_4_relline_lp', 309: 'norm_4_rellinelp_nk', 310: 'norm_4_rellinering_nk', 311: 'norm_4_relxilldgrad_nk', 312: 'norm_4_relxilldisk_nk', 313: 'norm_4_relxillNS', 314: 'norm_4_relxillD_nk', 315: 'norm_4_relxillion_nk', 316: 'norm_4_relxillionCp_nk', 317: 'norm_4_relxilllpion_nk', 318: 'norm_4_relxilllpionCp_nk', 319: 'norm_4_relxillring_nkxillver', 320: 'norm_4_xillverCp', 321: 'norm_4_xillverD', 322: 'norm_4_xillverNS', 323: 'factor_1', 324: 'factor_2', 325: 'factor_3', 326: 'factor_4', 327: 'dGamma_1', 328: 'dGamma_2', 329: 'dGamma_3', 330: 'dGamma_4', 331: 'crabcorNorm', 332: 'crabcorNorm_1', 333: 'crabcorNorm_2', 334: 'crabcorNorm_3', 335: 'crabcorNorm_4'}\n",
      "dict2:\n",
      "{'MaxTau': 0, 'nH': 1, 'nH_2': 2, 'Tin': 3, 'Tin_1': 4, 'Tin_2': 5, 'Tin_3': 6, 'Tin_4': 7, 'norm_diskbb': 8, 'norm_1_diskbb': 9, 'norm_2_diskbb': 10, 'norm_3_diskbb': 11, 'Mbh': 12, 'Mdd': 13, 'Dbh': 14, 'FracSctr': 15, 'FracSctr_1': 16, 'FracSctr_2': 17, 'FracSctr_3': 18, 'FracSctr_4': 19, 'norm_cutoffpl': 20, 'kT_bb': 21, 'norm_nthComp': 22, 'norm_1_nthComp': 23, 'norm_2_nthComp': 24, 'norm_3_nthComp': 25, 'norm_4_nthComp': 26, 'T0': 27, 'kT': 28, 'norm_compTT': 29, 'cov_frac': 30, 'PhoIndex': 31, 'PhoIndex_1': 32, 'PhoIndex_2': 33, 'PhoIndex_3': 34, 'PhoIndex_4': 35, 'Gamma_tau': 36, 'Gamma': 37, 'Gamma_1': 38, 'Gamma_2': 39, 'Gamma_3': 40, 'Gamma_4': 41, 'gamma': 42, 'gamma_2': 43, 'kT_e': 44, 'kTe': 45, 'Ecut': 46, 'E_cut': 47, 'HighECut': 48, 'HighECut_2': 49, 'HighECut_3': 50, 'HighECut_4': 51, 'h': 52, 'Index1': 53, 'Index2': 54, 'Index3': 55, 'Rbr': 56, 'Rbr1': 57, 'Rbr2': 58, 'Rin': 59, 'a': 60, 'Incl': 61, 'i': 62, 'Afe': 63, 'xi_index': 64, 'refl_frac': 65, 'logN': 66, 'LineE': 67, 'LineE_2': 68, 'LineE_3': 69, 'LineE_4': 70, 'norm_gaussian': 71, 'norm_2_gaussian': 72, 'norm_3_gaussian': 73, 'norm_4_gaussian': 74, 'Sigma': 75, 'Sigma_2': 76, 'Sigma_3': 77, 'Sigma_4': 78, 'Xpos': 79, 'column': 80, 'rlogxi': 81, 'z': 82, 'logxi_relconv': 83, 'logxi_relconv_lp': 84, 'logxi_relxill': 85, 'logxi_relxillCp': 86, 'logxi_relxill_nk': 87, 'logxi_relxillCp_nk': 88, 'logxi_relxill_nk2': 89, 'logxi_relxilllp': 90, 'logxi_relxilllpCp': 91, 'logxi_relxilllp_nk': 92, 'logxi_relxilllpCp_nk': 93, 'logxi_relxilllpD_nk': 94, 'logxi_relline': 95, 'logxi_relline_nk': 96, 'logxi_rellinedisk_nk': 97, 'logxi_relline_lp': 98, 'logxi_rellinelp_nk': 99, 'logxi_rellinering_nk': 100, 'logxi_relxilldgrad_nk': 101, 'logxi_relxilldisk_nk': 102, 'logxi_relxillNS': 103, 'logxi_relxillD_nk': 104, 'logxi_relxillion_nk': 105, 'logxi_relxillionCp_nk': 106, 'logxi_relxilllpion_nk': 107, 'logxi_relxilllpionCp_nk': 108, 'logxi_relxillring_nkxillver': 109, 'logxi_xillverCp': 110, 'logxi_xillverD': 111, 'logxi_xillverNS': 112, 'logxi_2_relconv': 113, 'logxi_2_relconv_lp': 114, 'logxi_2_relxill': 115, 'logxi_2_relxillCp': 116, 'logxi_2_relxill_nk': 117, 'logxi_2_relxillCp_nk': 118, 'logxi_2_relxill_nk2': 119, 'logxi_2_relxilllp': 120, 'logxi_2_relxilllpCp': 121, 'logxi_2_relxilllp_nk': 122, 'logxi_2_relxilllpCp_nk': 123, 'logxi_2_relxilllpD_nk': 124, 'logxi_2_relline': 125, 'logxi_2_relline_nk': 126, 'logxi_2_rellinedisk_nk': 127, 'logxi_2_relline_lp': 128, 'logxi_2_rellinelp_nk': 129, 'logxi_2_rellinering_nk': 130, 'logxi_2_relxilldgrad_nk': 131, 'logxi_2_relxilldisk_nk': 132, 'logxi_2_relxillNS': 133, 'logxi_2_relxillD_nk': 134, 'logxi_2_relxillion_nk': 135, 'logxi_2_relxillionCp_nk': 136, 'logxi_2_relxilllpion_nk': 137, 'logxi_2_relxilllpionCp_nk': 138, 'logxi_2_relxillring_nkxillver': 139, 'logxi_2_xillverCp': 140, 'logxi_2_xillverD': 141, 'logxi_2_xillverNS': 142, 'logxi_3_relconv': 143, 'logxi_3_relconv_lp': 144, 'logxi_3_relxill': 145, 'logxi_3_relxillCp': 146, 'logxi_3_relxill_nk': 147, 'logxi_3_relxillCp_nk': 148, 'logxi_3_relxill_nk2': 149, 'logxi_3_relxilllp': 150, 'logxi_3_relxilllpCp': 151, 'logxi_3_relxilllp_nk': 152, 'logxi_3_relxilllpCp_nk': 153, 'logxi_3_relxilllpD_nk': 154, 'logxi_3_relline': 155, 'logxi_3_relline_nk': 156, 'logxi_3_rellinedisk_nk': 157, 'logxi_3_relline_lp': 158, 'logxi_3_rellinelp_nk': 159, 'logxi_3_rellinering_nk': 160, 'logxi_3_relxilldgrad_nk': 161, 'logxi_3_relxilldisk_nk': 162, 'logxi_3_relxillNS': 163, 'logxi_3_relxillD_nk': 164, 'logxi_3_relxillion_nk': 165, 'logxi_3_relxillionCp_nk': 166, 'logxi_3_relxilllpion_nk': 167, 'logxi_3_relxilllpionCp_nk': 168, 'logxi_3_relxillring_nkxillver': 169, 'logxi_3_xillverCp': 170, 'logxi_3_xillverD': 171, 'logxi_3_xillverNS': 172, 'logxi_4_relconv': 173, 'logxi_4_relconv_lp': 174, 'logxi_4_relxill': 175, 'logxi_4_relxillCp': 176, 'logxi_4_relxill_nk': 177, 'logxi_4_relxillCp_nk': 178, 'logxi_4_relxill_nk2': 179, 'logxi_4_relxilllp': 180, 'logxi_4_relxilllpCp': 181, 'logxi_4_relxilllp_nk': 182, 'logxi_4_relxilllpCp_nk': 183, 'logxi_4_relxilllpD_nk': 184, 'logxi_4_relline': 185, 'logxi_4_relline_nk': 186, 'logxi_4_rellinedisk_nk': 187, 'logxi_4_relline_lp': 188, 'logxi_4_rellinelp_nk': 189, 'logxi_4_rellinering_nk': 190, 'logxi_4_relxilldgrad_nk': 191, 'logxi_4_relxilldisk_nk': 192, 'logxi_4_relxillNS': 193, 'logxi_4_relxillD_nk': 194, 'logxi_4_relxillion_nk': 195, 'logxi_4_relxillionCp_nk': 196, 'logxi_4_relxilllpion_nk': 197, 'logxi_4_relxilllpionCp_nk': 198, 'logxi_4_relxillring_nkxillver': 199, 'logxi_4_xillverCp': 200, 'logxi_4_xillverD': 201, 'logxi_4_xillverNS': 202, 'norm_relconv': 203, 'norm_relconv_lp': 204, 'norm_relxill': 205, 'norm_relxillCp': 206, 'norm_relxill_nk': 207, 'norm_relxillCp_nk': 208, 'norm_relxill_nk2': 209, 'norm_relxilllp': 210, 'norm_relxilllpCp': 211, 'norm_relxilllp_nk': 212, 'norm_relxilllpCp_nk': 213, 'norm_relxilllpD_nk': 214, 'norm_relline': 215, 'norm_relline_nk': 216, 'norm_rellinedisk_nk': 217, 'norm_relline_lp': 218, 'norm_rellinelp_nk': 219, 'norm_rellinering_nk': 220, 'norm_relxilldgrad_nk': 221, 'norm_relxilldisk_nk': 222, 'norm_relxillNS': 223, 'norm_relxillD_nk': 224, 'norm_relxillion_nk': 225, 'norm_relxillionCp_nk': 226, 'norm_relxilllpion_nk': 227, 'norm_relxilllpionCp_nk': 228, 'norm_relxillring_nkxillver': 229, 'norm_xillverCp': 230, 'norm_xillverD': 231, 'norm_xillverNS': 232, 'norm_2_relconv': 233, 'norm_2_relconv_lp': 234, 'norm_2_relxill': 235, 'norm_2_relxillCp': 236, 'norm_2_relxill_nk': 237, 'norm_2_relxillCp_nk': 238, 'norm_2_relxill_nk2': 239, 'norm_2_relxilllp': 240, 'norm_2_relxilllpCp': 241, 'norm_2_relxilllp_nk': 242, 'norm_2_relxilllpCp_nk': 243, 'norm_2_relxilllpD_nk': 244, 'norm_2_relline': 245, 'norm_2_relline_nk': 246, 'norm_2_rellinedisk_nk': 247, 'norm_2_relline_lp': 248, 'norm_2_rellinelp_nk': 249, 'norm_2_rellinering_nk': 250, 'norm_2_relxilldgrad_nk': 251, 'norm_2_relxilldisk_nk': 252, 'norm_2_relxillNS': 253, 'norm_2_relxillD_nk': 254, 'norm_2_relxillion_nk': 255, 'norm_2_relxillionCp_nk': 256, 'norm_2_relxilllpion_nk': 257, 'norm_2_relxilllpionCp_nk': 258, 'norm_2_relxillring_nkxillver': 259, 'norm_2_xillverCp': 260, 'norm_2_xillverD': 261, 'norm_2_xillverNS': 262, 'norm_3_relconv': 263, 'norm_3_relconv_lp': 264, 'norm_3_relxill': 265, 'norm_3_relxillCp': 266, 'norm_3_relxill_nk': 267, 'norm_3_relxillCp_nk': 268, 'norm_3_relxill_nk2': 269, 'norm_3_relxilllp': 270, 'norm_3_relxilllpCp': 271, 'norm_3_relxilllp_nk': 272, 'norm_3_relxilllpCp_nk': 273, 'norm_3_relxilllpD_nk': 274, 'norm_3_relline': 275, 'norm_3_relline_nk': 276, 'norm_3_rellinedisk_nk': 277, 'norm_3_relline_lp': 278, 'norm_3_rellinelp_nk': 279, 'norm_3_rellinering_nk': 280, 'norm_3_relxilldgrad_nk': 281, 'norm_3_relxilldisk_nk': 282, 'norm_3_relxillNS': 283, 'norm_3_relxillD_nk': 284, 'norm_3_relxillion_nk': 285, 'norm_3_relxillionCp_nk': 286, 'norm_3_relxilllpion_nk': 287, 'norm_3_relxilllpionCp_nk': 288, 'norm_3_relxillring_nkxillver': 289, 'norm_3_xillverCp': 290, 'norm_3_xillverD': 291, 'norm_3_xillverNS': 292, 'norm_4_relconv': 293, 'norm_4_relconv_lp': 294, 'norm_4_relxill': 295, 'norm_4_relxillCp': 296, 'norm_4_relxill_nk': 297, 'norm_4_relxillCp_nk': 298, 'norm_4_relxill_nk2': 299, 'norm_4_relxilllp': 300, 'norm_4_relxilllpCp': 301, 'norm_4_relxilllp_nk': 302, 'norm_4_relxilllpCp_nk': 303, 'norm_4_relxilllpD_nk': 304, 'norm_4_relline': 305, 'norm_4_relline_nk': 306, 'norm_4_rellinedisk_nk': 307, 'norm_4_relline_lp': 308, 'norm_4_rellinelp_nk': 309, 'norm_4_rellinering_nk': 310, 'norm_4_relxilldgrad_nk': 311, 'norm_4_relxilldisk_nk': 312, 'norm_4_relxillNS': 313, 'norm_4_relxillD_nk': 314, 'norm_4_relxillion_nk': 315, 'norm_4_relxillionCp_nk': 316, 'norm_4_relxilllpion_nk': 317, 'norm_4_relxilllpionCp_nk': 318, 'norm_4_relxillring_nkxillver': 319, 'norm_4_xillverCp': 320, 'norm_4_xillverD': 321, 'norm_4_xillverNS': 322, 'factor_1': 323, 'factor_2': 324, 'factor_3': 325, 'factor_4': 326, 'dGamma_1': 327, 'dGamma_2': 328, 'dGamma_3': 329, 'dGamma_4': 330, 'crabcorNorm': 331, 'crabcorNorm_1': 332, 'crabcorNorm_2': 333, 'crabcorNorm_3': 334, 'crabcorNorm_4': 335}\n",
      "key_temp_1:\n",
      "[43, 42, 82, 211, 80, 324, 52, 1, 45, 81, 63, 66, 61, 91, 65, 60, 75, 71, 67, 325]\n",
      "keys:\n",
      "['nH', 'gamma', 'gamma_2', 'kTe', 'h', 'a', 'Incl', 'Afe', 'refl_frac', 'logN', 'LineE', 'norm_gaussian', 'Sigma', 'column', 'rlogxi', 'z', 'logxi_relxilllpCp', 'norm_relxilllpCp', 'factor_2', 'factor_3']\n",
      "elements: \n",
      "[{'nH': '$19.2_{-0.5}^{+0.5}$', 'column': '$4.6_{-2.4}^{+2.8}\\\\times10^{22}$', 'rlogxi': '$2.71_{-0.08}^{+0.3}$', 'z': '$-0.010_{-0.011}^{+0.009}$', 'Incl': '$66.6_{-2.1}^{+1.6}$', 'a': '$0.998_{-0.013}^{+P}$', 'h': '$2.0_{-P}^{+0.6}$', 'gamma': '$1.45_{-0.04}^{+0.04}$', 'logxi_relxilllpCp': '$3.07_{-0.16}^{+0.08}$', 'logN': '$15.0_{-P}^{+1.7}$', 'Afe': '$0.5_{-P}^{+0.1}$', 'kTe': '$63.1_{-6}^{+8}$', 'refl_frac': '$1.5_{-0.6}^{+0.3}$', 'norm_relxilllpCp': '$0.149_{-0.023}^{+0.005}$', 'LineE': '$6.48_{-0.15}^{+0.11}$', 'Sigma': '$0.42_{-0.06}^{+0.09}$', 'norm_gaussian': '$0.0014_{-0.0004}^{+0.0004}$', 'factor_2': '$0.71_{-0.07}^{+0.08}$', 'gamma_2': '$1.69_{-0.02}^{+0.03}$', 'factor_3': '$0.70_{-0.09}^{+0.08}$'}, {'nH': '$19.2_{-0.5}^{+0.3}$', 'column': '$4.2_{-2.1}^{+1.3}\\\\times10^{22}$', 'rlogxi': '$2.69_{-0.09}^{+0.3}$', 'z': '$-0.01_{-0.01}^{+0.01}$', 'Incl': '$65.3_{-2.1}^{+1.7}$', 'a': '$1.0_{-0.1}^{+P}$', 'h': '$2.0_{-P}^{+0.6}$', 'gamma': '$1.45_{-0.03}^{+0.03}$', 'logxi_relxilllpCp': '$3.09_{-0.18}^{+0.09}$', 'logN': '$15.0_{-P}^{+1.6}$', 'Afe': '$0.50_{-P}^{+0.07}$', 'kTe': '$64.0_{-5}^{+8}$', 'refl_frac': '$0.94_{-0.2}^{+0.17}$', 'norm_relxilllpCp': '$0.153_{-0.024}^{+0.04}$', 'LineE': '$6.45_{-0.15}^{+0.13}$', 'Sigma': '$0.39_{-0.11}^{+0.1}$', 'norm_gaussian': '$0.0013_{-0.0004}^{+0.0005}$', 'factor_2': '$0.69_{-0.07}^{+0.08}$', 'gamma_2': '$1.686_{-0.018}^{+0.026}$', 'factor_3': '$0.68_{-0.07}^{+0.08}$'}]\n"
     ]
    }
   ],
   "source": [
    "# type your txt files list:\n",
    "# infiles = ['relionCp-nk_best-fit.txt','relionCp-nk_q2-3_best-fit.txt','relionCp-nk+xillcp_logxi-0_best-fit.txt',\n",
    "#            'simp_disk+relionCp-nk_q2-free_best-fit.txt','mo_2B-1.txt','simp_disk+relionCp-nk_+xillcp_q2-free_best-fit.txt']\n",
    "# model_name = ['1A','1B','1C','2A','2B','2C']\n",
    "infiles = ['swiftJ1658_RTOFF.txt','swiftJ1658_RTON.txt']\n",
    "model_name = ['mo1','mo2']\n",
    "\n",
    "print_final_latex_code(infiles,model_name,debug=True,output_filename='latex_table_output.txt')\n",
    "\n",
    "# find your latex codes in 'latex_table_output.txt'.\n",
    "# if you encounter error messages, please set 'debug=True' in function 'print_final_latex_code'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0892ec632cc5bc01ba49379c22c0b312adff907935143a2b003e64b1c0e2b2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
